# complete version 
# cat consul-prod.yaml
global:
  name: consul
  datacenter: central-primary-infra

  tls:
    enabled: true
    enableAutoEncrypt: true
    httpsOnly: true

  acls:
    manageSystemACLs: true
  authMethod:
     enable: true
     name: consul-k8s-component-auth-method
   # bootstrapToken:
   #   secretName: consul-bootstrap-acl-token
   #   secretKey: token

  peering:
    enabled: true

  meshGateway:
    enabled: true

ui:
  enabled: true

controller:
  enabled: true

dataplane:
  enabled: true

server:
  enabled: true
  replicas: 3
  exposeGossipAndRPC:
    enabled: true
  bootstrapExpect: 3
  exposeService:
    type: LoadBalancer
  annotations: 
      io.cilium/lb-ipam-ips: "192.168.1.82"
    # REQUIRED: Label for the Cilium IP Pool selector
  labels:
      io.cilium/lb-ipam-ips: "true"
  extraConfig: |
    {
      "acl": {
        "enabled": true,
        "default_policy": "allow",
        "enable_token_persistence": true
      }
    }

client:
  enabled: true
  grpc: true
  extraConfig: |
    {
      "verify_incoming": false,
      "verify_outgoing": true,
      "verify_server_hostname": true
    }

connectInject:
  enabled: true
  apiGateway:
    managedGatewayClass:
      serviceType: LoadBalancer
      annotations:
        io.cilium/lb-ipam-ips: "192.168.1.74"
      # REQUIRED: Label for the Cilium IP Pool selector
      labels:
        io.cilium/lb-ipam-ips: "true"
  default: true
  k8sAllowNamespaces: ["cattle-system","kube-system","consul"]
  tls:
    enabled: true

syncCatalog:
  enabled: true
  toConsul: true
  toK8S: false
  consulNodeName: "omni-infra"
  k8sAllowNamespaces: ["cattle-system","kube-system","consul"]
  k8sDenyNamespaces: ["default"]
  addK8SNamespaceSuffix: false
  tls:
    enabled: true

meshGateway:
  enabled: true
  replicas: 2
  service:
    type: LoadBalancer
    # chart 1.9.x expects a STRING here, not a map
    annotations: |
      service.cilium.io/global: "true"
      io.cilium/lb-ipam-ips: "10.19.143.100"
      consul.hashicorp.com/connect-inject: "true"
      consul.hashicorp.com/mesh-inject: "true"
    labels:
        io.cilium/lb-ipam-ips: "true"  
  hostNetwork: false



---
helm upgrade consul hashicorp/consul --namespace consul --values consul-prod.yaml --atomic --timeout 10m
Flag --atomic has been deprecated, use --rollback-on-failure instead
level=WARN msg="unable to find exact version; falling back to closest available version" chart=consul requested="" selected=1.9.2
Error: UPGRADE FAILED: could not get server version from Kubernetes: an error on the server ("<html>\r\n<head><title>502 Bad Gateway</title></head>\r\n<body>\r\n<center><h1>502 Bad Gateway</h1></center>\r\n<hr><center>nginx/1.24.0 (Ubuntu)</center>\r\n</body>\r\n</html>") has prevented the request from succeeding

$ cat consul-prod.yaml
global:
  name: consul
  datacenter: central-primary-infra

  tls:
    enabled: true
    enableAutoEncrypt: true
    httpsOnly: true

  acls:
    manageSystemACLs: true
  authMethod:
     enable: true
     name: consul-k8s-component-auth-method
   # bootstrapToken:
   #   secretName: consul-bootstrap-acl-token
   #   secretKey: token

  peering:
    enabled: true

  meshGateway:
    enabled: true

ui:
  enabled: true

controller:
  enabled: true

dataplane:
  enabled: true

server:
  enabled: true
  replicas: 3
  bootstrapExpect: 3
  exposeGossipAndRPC:
    enabled: true
    type: LoadBalancer
    service:
      annotations: |
        lbipam.cilium.io/ips: "192.168.1.82"
     # REQUIRED: Label for the Cilium IP Pool selector
      labels:
        io.cilium/lb-ipam-ips: "true"


 # exposeService:
 #   type: LoadBalancer

  extraConfig: |
    {
      "acl": {
        "enabled": true,
        "default_policy": "allow",
        "enable_token_persistence": true
      }
    }

client:
  enabled: true
  grpc: true
  extraConfig: |
    {
      "verify_incoming": false,
      "verify_outgoing": true,
      "verify_server_hostname": true
    }

connectInject:
  enabled: true
  apiGateway:
    managedGatewayClass:
      serviceType: LoadBalancer
      annotations: |
        lbipam.cilium.io/ips: "192.168.1.74"
      # REQUIRED: Label for the Cilium IP Pool selector
      labels:
          io.cilium/lb-ipam-ips: "true"
  default: true
  k8sAllowNamespaces: ["cattle-system","kube-system","consul"]
  tls:
    enabled: true

syncCatalog:
  enabled: true
  toConsul: true
  toK8S: false
  consulNodeName: "omni-infra"
  k8sAllowNamespaces: ["cattle-system","kube-system","consul"]
  k8sDenyNamespaces: ["default"]
  addK8SNamespaceSuffix: false
  tls:
    enabled: true

meshGateway:
  enabled: true
  replicas: 2
  service:
    type: LoadBalancer
    # chart 1.9.x expects a STRING here, not a map
    annotations: |
      service.cilium.io/global: "true"
      lbipam.cilium.io/ips: "10.19.143.100"
      consul.hashicorp.com/connect-inject: "true"
      consul.hashicorp.com/mesh-inject: "true"
    labels:
        io.cilium/lb-ipam-ips: "true"
  hostNetwork: false

kubectl label nodes --all node.kubernetes.io/exclude-from-external-load-balancers-
helm upgrade consul hashicorp/consul \
  --namespace consul \
  --values consul-prod.yaml \
  --rollback-on-failure \
  --timeout 10m

helm template consul hashicorp/consul -f consul-prod.yaml --version 1.9.2 | grep -E "kind: Service|name: consul-server-expose|name: consul-mesh-gateway"
# Check that all 3 LBs have their IPs
kubectl get svc -n consul -l io.cilium/lb-ipam-ips=true

# Check that the Sync process is using your cluster name
kubectl logs -n consul -l app=consul,component=sync-catalog | grep "omni-infra"


kubectl label svc consul-server io.cilium/lb-ipam-ips=true -n consul
kubectl label svc consul-mesh-gateway io.cilium/lb-ipam-ips=true -n consul

##
gateway api 
kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.2.1/standard-install.yaml
kubectl rollout restart deployment consul-connect-injector -n consul



apiVersion: ://api-gateway.consul.hashicorp.com
kind: GatewayClassConfig
metadata:
  name: consul-api-gateway # This matches the name in your parametersRef
  namespace: consul
spec:
  # This tells the controller to use your .74 IP
  serviceType: LoadBalancer
  serviceAnnotations:
    lbipam.cilium.io/ips: "192.168.1.74"



2026-01-22T09:55:29.583Z    ERROR    error updating status    {"gateway": {"name":"shared-hub-gateway","namespace":"infra-system"}, "error": "Gateway.gateway.networking │
│ github.com/hashicorp/consul-k8s/control-plane/api-gateway/controllers.(*GatewayController).Reconcile                                                                     │
│     /home/runner/work/consul-k8s/consul-k8s/control-plane/api-gateway/controllers/gateway_controller.go:322                                                              │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile                                                                                           │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:119                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler                                                                                    │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:316                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem                                                                                 │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:266                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2                                                                                       │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:227                                                             │
│ 2026-01-22T09:55:29.583Z    ERROR    Reconciler error    {"controller": "gateway", "controllerGroup": "gateway.networking.k8s.io", "controllerKind": "Gateway", "Gateway │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler                                                                                    │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:329                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem                                                                                 │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:266                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2                                                                                       │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:227                                                             │
│ 2026-01-22T09:55:34.727Z    ERROR    error updating status    {"gateway": {"name":"shared-hub-gateway","namespace":"infra-system"}, "error": "Gateway.gateway.networking │
│ github.com/hashicorp/consul-k8s/control-plane/api-gateway/controllers.(*GatewayController).Reconcile                                                                     │
│     /home/runner/work/consul-k8s/consul-k8s/control-plane/api-gateway/controllers/gateway_controller.go:322                                                              │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile                                                                                           │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:119                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler                                                                                    │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:316                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem 




│ 2026-01-22T09:55:23.547Z    INFO    Starting workers    {"controller": "gateway", "controllerGroup": "gateway.networking.k8s.io", "controllerKind": "Gateway", "worker c │
│ 2026-01-22T09:55:23.547Z    INFO    Starting workers    {"controller": "ingressgateway", "controllerGroup": "consul.hashicorp.com", "controllerKind": "IngressGateway",  │
│ 2026-01-22T09:55:23.547Z    INFO    Starting workers    {"controller": "servicedefaults", "controllerGroup": "consul.hashicorp.com", "controllerKind": "ServiceDefaults" │
│ 2026-01-22T09:55:23.549Z    INFO    controller.endpoints    retrieved    {"name": "consul-server", "ns": "consul"}                                                       │
│ 2026-01-22T09:55:23.646Z    INFO    controller.endpoints    retrieved    {"name": "consul-ui", "ns": "consul"}                                                           │
│ 2026-01-22T09:55:23.647Z    INFO    controller.endpoints    retrieved    {"name": "consul-expose-servers", "ns": "consul"}                                               │
│ 2026-01-22T09:55:23.648Z    INFO    controller.endpoints    retrieved    {"name": "imperative-api-extension", "ns": "cattle-system"}                                     │
│ 2026-01-22T09:55:23.649Z    INFO    controller.endpoints    retrieved    {"name": "rancher", "ns": "cattle-system"}                                                      │
│ 2026-01-22T09:55:23.650Z    INFO    controller.endpoints    retrieved    {"name": "rancher-webhook", "ns": "cattle-system"}                                              │
│ 2026-01-22T09:55:23.651Z    INFO    controller.endpoints    retrieved    {"name": "consul-connect-injector", "ns": "consul"}                                             │
│ 2026-01-22T09:55:23.651Z    INFO    controller.endpoints    retrieved    {"name": "consul-mesh-gateway", "ns": "consul"}                                                 │
│ 2026-01-22T09:55:23.651Z    INFO    controller.endpoints    registering gateway with Consul    {"name": "mesh-gateway", "id": ""}                                        │
│ 2026-01-22T09:55:23.747Z    INFO    controller.endpoints    registering gateway with Consul    {"name": "mesh-gateway", "id": ""}                                        │
│ 2026-01-22T09:55:24.060Z    INFO    KubeAPIWarningLogger    would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "shared-hub-gate │
│ 2026-01-22T09:55:24.069Z    ERROR    error updating status    {"gateway": {"name":"shared-hub-gateway","namespace":"infra-system"}, "error": "Gateway.gateway.networking │
│ github.com/hashicorp/consul-k8s/control-plane/api-gateway/controllers.(*GatewayController).Reconcile                                                                     │
│     /home/runner/work/consul-k8s/consul-k8s/control-plane/api-gateway/controllers/gateway_controller.go:322                                                              │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile                                                                                           │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:119                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler                                                                                    │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:316                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem                                                                                 │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:266                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2                                                                                       │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:227                                                             │
│ 2026-01-22T09:55:24.069Z    ERROR    Reconciler error    {"controller": "gateway", "controllerGroup": "gateway.networking.k8s.io", "controllerKind": "Gateway", "Gateway │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler                                                                                    │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:329                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem                                                                                 │
│     /home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.5/pkg/internal/controller/controller.go:266                                                             │
│ sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2  


kubectl label namespace infra-system pod-security.kubernetes.io/enforce=privileged --overwrite=true
kubectl label namespace infra-system pod-security.kubernetes.io/warn=privileged --overwrite=true

consul  consul          26              2026-01-22 09:41:11.8096256 +0000 UTC   deployed        consul-1.9.2    1.22.2

$ helm get manifest consul -n consul | grep -n gateway-controller
1095:                  description: "ControllerName is the name of the controller that is managing Gateways of this class. The value of this field MUST be a domain prefixed path. \n Example: \"example.net/gateway-controller\". \n This field is not mutable and cannot be empty. \n Support: Core"
1240:                  description: "ControllerName is the name of the controller that is managing Gateways of this class. The value of this field MUST be a domain prefixed path. \n Example: \"example.net/gateway-controller\". \n This field is not mutable and cannot be empty. \n Support: Core"
3243:                        description: "ControllerName is a domain/path string that indicates the name of the controller that wrote this status. This corresponds with the controllerName field on GatewayClass. \n Example: \"example.net/gateway-controller\". \n The format of this field is DOMAIN \"/\" PATH, where DOMAIN and PATH are valid Kubernetes names (https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names). \n Controllers MUST populate this field when writing status. Controllers should ensure that entries to status populated with their ControllerName are cleaned up when they are no longer necessary."
4216:                        description: "ControllerName is a domain/path string that indicates the name of the controller that wrote this status. This corresponds with the controllerName field on GatewayClass. \n Example: \"example.net/gateway-controller\". \n The format of this field is DOMAIN \"/\" PATH, where DOMAIN and PATH are valid Kubernetes names (https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names). \n Controllers MUST populate this field when writing status. Controllers should ensure that entries to status populated with their ControllerName are cleaned up when they are no longer necessary."
5155:                        description: "ControllerName is a domain/path string that indicates the name of the controller that wrote this status. This corresponds with the controllerName field on GatewayClass. \n Example: \"example.net/gateway-controller\". \n The format of this field is DOMAIN \"/\" PATH, where DOMAIN and PATH are valid Kubernetes names (https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names). \n Controllers MUST populate this field when writing status. Controllers should ensure that entries to status populated with their ControllerName are cleaned up when they are no longer necessary."
10033:                        description: "ControllerName is a domain/path string that indicates the name of the controller that wrote this status. This corresponds with the controllerName field on GatewayClass. \n Example: \"example.net/gateway-controller\". \n The format of this field is DOMAIN \"/\" PATH, where DOMAIN and PATH are valid Kubernetes names (https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names). \n Controllers MUST populate this field when writing status. Controllers should ensure that entries to status populated with their ControllerName are cleaned up when they are no longer necessary."
10472:                        description: "ControllerName is a domain/path string that indicates the name of the controller that wrote this status. This corresponds with the controllerName field on GatewayClass. \n Example: \"example.net/gateway-controller\". \n The format of this field is DOMAIN \"/\" PATH, where DOMAIN and PATH are valid Kubernetes names (https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names). \n Controllers MUST populate this field when writing status. Controllers should ensure that entries to status populated with their ControllerName are cleaned up when they are no longer necessary."
11018:                        description: "ControllerName is a domain/path string that indicates the name of the controller that wrote this status. This corresponds with the controllerName field on GatewayClass. \n Example: \"example.net/gateway-controller\". \n The format of this field is DOMAIN \"/\" PATH, where DOMAIN and PATH are valid Kubernetes names (https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names). \n Controllers MUST populate this field when writing status. Controllers should ensure that entries to status populated with their ControllerName are cleaned up when they are no longer necessary."

kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.1.0/standard-install.yaml
kubectl apply --server-side -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.4.1/standard-install.yaml
kubectl get crd gateways.gateway.networking.k8s.io -o jsonpath='{.spec.versions[?(@.storage==true)].name}'


 kubectl apply --server-side -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.4.1/standard-install.yaml

2026-01-22T11:53:32.082Z    INFO    pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:229: failed to list *v1beta1.Gateway:  ││ 2026-01-22T11:53:32.082Z    ERROR    pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:229: Failed to watch *v1beta1.Gateway │
│ k8s.io/client-go/tools/cache.DefaultWatchErrorHandler                                                                                ││     /home/runner/go/pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:147                                                    │
│ k8s.io/client-go/tools/cache.(*Reflector).Run.func1                                                                                  ││     /home/runner/go/pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:292                                                    │
│ k8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1                                                                                 ││     /home/runner/go/pkg/mod/k8s.io/apimachinery@v0.29.8/pkg/util/wait/backoff.go:226                                                 │
│ k8s.io/apimachinery/pkg/util/wait.BackoffUntil                                                                                       ││     /home/runner/go/pkg/mod/k8s.io/apimachinery@v0.29.8/pkg/util/wait/backoff.go:227                                                 │
│ k8s.io/client-go/tools/cache.(*Reflector).Run                                                                                        ││     /home/runner/go/pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:290                                                    │
│ k8s.io/client-go/tools/cache.(*controller).Run.(*Group).StartWithChannel.func2                                                       ││     /home/runner/go/pkg/mod/k8s.io/apimachinery@v0.29.8/pkg/util/wait/wait.go:55                                                     │
│ k8s.io/apimachinery/pkg/util/wait.(*Group).Start.func1                                                                               ││     /home/runner/go/pkg/mod/k8s.io/apimachinery@v0.29.8/pkg/util/wait/wait.go:72                                                     │
│ 2026-01-22T11:53:43.059Z    INFO    pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:229: failed to list *v1beta1.HTTPRoute ││ 2026-01-22T11:53:43.059Z    ERROR    pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:229: Failed to watch *v1beta1.HTTPRou │
│ k8s.io/client-go/tools/cache.DefaultWatchErrorHandler                                                                                ││     /home/runner/go/pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:147                                                    │
│ k8s.io/client-go/tools/cache.(*Reflector).Run.func1                                                                                  ││     /home/runner/go/pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:292                                                    │
│ k8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1                                                                                 │
│     /home/runner/go/pkg/mod/k8s.io/apimachinery@v0.29.8/pkg/util/wait/backoff.go:226                                                 │
│ k8s.io/apimachinery/pkg/util/wait.BackoffUntil                                                                                       │
│     /home/runner/go/pkg/mod/k8s.io/apimachinery@v0.29.8/pkg/util/wait/backoff.go:227                                                 │
│ k8s.io/client-go/tools/cache.(*Reflector).Run                                                                                        │
│     /home/runner/go/pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:290                                                    │
│ k8s.io/client-go/tools/cache.(*controller).Run.(*Group).StartWithChannel.func2                                                       │
│     /home/runner/go/pkg/mod/k8s.io/apimachinery@v0.29.8/pkg/util/wait/wait.go:55                                                     │
│ k8s.io/apimachinery/pkg/util/wait.(*Group).Start.func1                                                                               │
│     /home/runner/go/pkg/mod/k8s.io/apimachinery@v0.29.8/pkg/util/wait/wait.go:72                                                     │
│ 2026-01-22T11:53:45.540Z    INFO    pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:229: failed to list *v1beta1.Reference │
│ 2026-01-22T11:53:45.541Z    ERROR    pkg/mod/k8s.io/client-go@v0.29.8/tools/cache/reflector.go:229: Failed to watch *v1beta1.Referen │
│ k8s.io/client-go/tools/cache.DefaultWatchErrorHandler    

kubectl logs -n kube-system -l io.cilium.k8s.operator.partof=cilium-operator | grep -i "gateway"

$ kubectl logs -n kube-system cilium-operator-5dd7d68d75-dm5vw  | grep -i "gateway"
time=2026-01-22T14:39:28.782875737Z level=info msg="  --egress-gateway-reconciliation-trigger-interval='1s'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.78292522Z level=info msg="  --enable-egress-gateway='false'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.782939171Z level=info msg="  --enable-gateway-api='true'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.782942526Z level=info msg="  --enable-gateway-api-alpn='false'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.782946182Z level=info msg="  --enable-gateway-api-app-protocol='false'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.782949827Z level=info msg="  --enable-gateway-api-proxy-protocol='false'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.782953422Z level=info msg="  --enable-gateway-api-secrets-sync='true'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.783009166Z level=info msg="  --enable-ipv4-egress-gateway='false'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.783146763Z level=info msg="  --gateway-api-hostnetwork-enabled='false'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.783151139Z level=info msg="  --gateway-api-hostnetwork-nodelabelselector=''" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.783154815Z level=info msg="  --gateway-api-secrets-namespace='cilium-secrets'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.78315855Z level=info msg="  --gateway-api-service-externaltrafficpolicy='Cluster'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.783162256Z level=info msg="  --gateway-api-xff-num-trusted-hops='0'" subsys=cilium-operator-generic
time=2026-01-22T14:39:28.79905652Z level=info msg="Checking for required and optional GatewayAPI resources" module=operator.operator-controlplane.leader-lifecycle.gateway-api requiredGVK="[gateway.networking.k8s.io/v1, Kind=gatewayclasses gateway.networking.k8s.io/v1, Kind=gateways gateway.networking.k8s.io/v1, Kind=httproutes gateway.networking.k8s.io/v1, Kind=grpcroutes gateway.networking.k8s.io/v1beta1, Kind=referencegrants]" optionalGVK="[gateway.networking.k8s.io/v1alpha2, Kind=tlsroutes multicluster.x-k8s.io/v1alpha1, Kind=serviceimports]"
time=2026-01-22T14:39:28.825922783Z level=error msg="Required GatewayAPI resources are not found, please refer to docs for installation instructions" module=operator.operator-controlplane.leader-lifecycle.gateway-api error="CRD \"gatewayclasses.gateway.networking.k8s.io\" does not have version \"v1\"\nCRD \"gateways.gateway.networking.k8s.io\" does not have version \"v1\"\nCRD \"httproutes.gateway.networking.k8s.io\" does not have version \"v1\"\nCRD \"grpcroutes.gateway.networking.k8s.io\" does not have version \"v1\""
time=2026-01-22T14:39:38.025105123Z level=info msg="CRD (CustomResourceDefinition) is installed and up-to-date" module=operator.operator-controlplane.leader-lifecycle.create-crds name=ciliumgatewayclassconfigs.cilium.io

kubectl apply --server-side -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.4.1/experimental-install.yaml --force
":null}}

to:
Resource: "apiextensions.k8s.io/v1, Resource=customresourcedefinitions", GroupVersionKind: "apiextensions.k8s.io/v1, Kind=CustomResourceDefinition"
Name: "httproutes.gateway.networking.k8s.io", Namespace: ""
for: "https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.4.1/experimental-install.yaml": context deadline exceeded

$  kubectl get crd gateways.gateway.networking.k8s.io -o jsonpath='{.status.storedVersions}'
["v1beta1","v1"]
$ kubectl rollout restart deployment cilium-operator -n kube-system
deployment.apps/cilium-operator restarted

$ kubectl get gatewayclass
No resources found

$ kubectl get gatewayclass
No resources found

$ kubectl logs -n kube-system cilium-operator-5dd7d68d75-dm5vw  | grep -i "gateway"
error: error from server (NotFound): pods "cilium-operator-5dd7d68d75-dm5vw" not found in namespace "kube-system"

$ kubectl get gatewayclass
No resources found

$ kubectl logs -n kube-system cilium-operator-75d75c9b94-gr9jw  | grep -i "gateway"
time=2026-01-22T14:55:11.241313818Z level=info msg="  --egress-gateway-reconciliation-trigger-interval='1s'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241364142Z level=info msg="  --enable-egress-gateway='false'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241391693Z level=info msg="  --enable-gateway-api='true'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241395038Z level=info msg="  --enable-gateway-api-alpn='false'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241398414Z level=info msg="  --enable-gateway-api-app-protocol='false'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241402039Z level=info msg="  --enable-gateway-api-proxy-protocol='false'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241405534Z level=info msg="  --enable-gateway-api-secrets-sync='true'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241460166Z level=info msg="  --enable-ipv4-egress-gateway='false'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241587125Z level=info msg="  --gateway-api-hostnetwork-enabled='false'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241591672Z level=info msg="  --gateway-api-hostnetwork-nodelabelselector=''" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241595337Z level=info msg="  --gateway-api-secrets-namespace='cilium-secrets'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241598882Z level=info msg="  --gateway-api-service-externaltrafficpolicy='Cluster'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.241602338Z level=info msg="  --gateway-api-xff-num-trusted-hops='0'" subsys=cilium-operator-generic
time=2026-01-22T14:55:11.257789285Z level=info msg="Checking for required and optional GatewayAPI resources" module=operator.operator-controlplane.leader-lifecycle.gateway-api requiredGVK="[gateway.networking.k8s.io/v1, Kind=gatewayclasses gateway.networking.k8s.io/v1, Kind=gateways gateway.networking.k8s.io/v1, Kind=httproutes gateway.networking.k8s.io/v1, Kind=grpcroutes gateway.networking.k8s.io/v1beta1, Kind=referencegrants]" optionalGVK="[gateway.networking.k8s.io/v1alpha2, Kind=tlsroutes multicluster.x-k8s.io/v1alpha1, Kind=serviceimports]"
time=2026-01-22T14:55:11.292883898Z level=error msg="Required GatewayAPI resources are not found, please refer to docs for installation instructions" module=operator.operator-controlplane.leader-lifecycle.gateway-api error="customresourcedefinitions.apiextensions.k8s.io \"httproutes.gateway.networking.k8s.io\" not found"
time=2026-01-22T14:55:20.503896762Z level=info msg="CRD (CustomResourceDefinition) is installed and up-to-date" module=operator.operator-controlplane.leader-lifecycle.create-crds name=ciliumgatewayclassconfigs.cilium.io




kubectl delete crd gateways.gateway.networking.k8s.io httproutes.gateway.networking.k8s.io gatewayclasses.gateway.networking.k8s.io grpcroutes.gateway.networking.k8s.io referencegrants.gateway.networking.k8s.io


 kubectl apply  -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.4.1/experimental-install.yaml --force
customresourcedefinition.apiextensions.k8s.io/backendtlspolicies.gateway.networking.k8s.io configured
customresourcedefinition.apiextensions.k8s.io/gatewayclasses.gateway.networking.k8s.io created
customresourcedefinition.apiextensions.k8s.io/gateways.gateway.networking.k8s.io created
customresourcedefinition.apiextensions.k8s.io/grpcroutes.gateway.networking.k8s.io created
customresourcedefinition.apiextensions.k8s.io/referencegrants.gateway.networking.k8s.io created
customresourcedefinition.apiextensions.k8s.io/tcproutes.gateway.networking.k8s.io configured
customresourcedefinition.apiextensions.k8s.io/tlsroutes.gateway.networking.k8s.io configured
customresourcedefinition.apiextensions.k8s.io/udproutes.gateway.networking.k8s.io configured
customresourcedefinition.apiextensions.k8s.io/xbackendtrafficpolicies.gateway.networking.x-k8s.io configured
customresourcedefinition.apiextensions.k8s.io/xlistenersets.gateway.networking.x-k8s.io configured
customresourcedefinition.apiextensions.k8s.io/xmeshes.gateway.networking.x-k8s.io configured
The CustomResourceDefinition "httproutes.gateway.networking.k8s.io" is invalid: metadata.annotations: Too long: may not be more than 262144 bytes


# Get the CRD name
CRD_NAME="gateways.gateway.networking.k8s.io"

# Remove the managedFields metadata that tracks previous ownership
kubectl patch crd $CRD_NAME --type=json -p='[{"op": "remove", "path": "/metadata/managedFields"}]'




 kubectl logs -n kube-system cilium-operator-8774b76f7-x4vx8   | grep -i "gateway"                                                                                         time=2026-01-22T15:17:10.184189309Z level=info msg="  --egress-gateway-reconciliation-trigger-interval='1s'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.184237682Z level=info msg="  --enable-egress-gateway='false'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.184254016Z level=info msg="  --enable-gateway-api='true'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.184257661Z level=info msg="  --enable-gateway-api-alpn='false'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.184261207Z level=info msg="  --enable-gateway-api-app-protocol='false'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.184264812Z level=info msg="  --enable-gateway-api-proxy-protocol='false'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.184268638Z level=info msg="  --enable-gateway-api-secrets-sync='true'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.184340596Z level=info msg="  --enable-ipv4-egress-gateway='false'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.184471713Z level=info msg="  --gateway-api-hostnetwork-enabled='false'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.184476308Z level=info msg="  --gateway-api-hostnetwork-nodelabelselector=''" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.184480294Z level=info msg="  --gateway-api-secrets-namespace='cilium-secrets'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.18448405Z level=info msg="  --gateway-api-service-externaltrafficpolicy='Cluster'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.184487806Z level=info msg="  --gateway-api-xff-num-trusted-hops='0'" subsys=cilium-operator-generic
time=2026-01-22T15:17:10.19995389Z level=info msg="Checking for required and optional GatewayAPI resources" module=operator.operator-controlplane.leader-lifecycle.gateway-api requiredGVK="[gateway.networking.k8s.io/v1, Kind=gatewayclasses gateway.networking.k8s.io/v1, Kind=gateways gateway.networking.k8s.io/v1, Kind=httproutes gateway.networking.k8s.io/v1, Kind=grpcroutes gateway.networking.k8s.io/v1beta1, Kind=referencegrants]" optionalGVK="[gateway.networking.k8s.io/v1alpha2, Kind=tlsroutes multicluster.x-k8s.io/v1alpha1, Kind=serviceimports]"
time=2026-01-22T15:17:10.254861776Z level=info msg="TLSRoute CRD is installed, TLSRoute support is enabled" module=operator.operator-controlplane.leader-lifecycle.gateway-api
time=2026-01-22T15:17:10.296093949Z level=info msg="Setting up Secret synchronization" module=operator.operator-controlplane.leader-lifecycle.secret-sync registrations="[*v2.CiliumClusterwideNetworkPolicy -> \"cilium-secrets\" *v2.CiliumNetworkPolicy -> \"cilium-secrets\" *v1.Gateway -> \"cilium-secrets\"]"






# Save as gateway-class.yaml
apiVersion: gateway.networking.k8s.io/v1
kind: GatewayClass
metadata:
  name: envoy-gateway
spec:
  controllerName: gateway.envoyproxy.io/gatewayclass-controller

# gateway.yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: cilium-ingress
  namespace: envoy-gateway-system
spec:
  gatewayClassName: envoy-gateway
  listeners:
    - name: grpc
      protocol: HTTP # Or HTTP if testing without certs
      port: 8502
      allowedRoutes:
        namespaces:
          from: All



apiVersion: gateway.networking.k8s.io/v1
kind: GRPCRoute
metadata:
  name: consul-grpc-route
  namespace: consul
spec:
  parentRefs:
    - name: cilium-ingress # Points to your Cilium Gateway
  rules:
    - matches:
        - method:
            service: "consul.v1.ConfigEntryService" # Or relevant Consul gRPC service
      backendRefs:
        - name: consul-server
          port: 8502

#########################################################################################################################################################

 helm upgrade consul hashicorp/consul --namespace consul --values consul-prod.yaml --rollback-on-failure --timeout 10m
level=WARN msg="unable to find exact version; falling back to closest available version" chart=consul requested="" selected=1.9.2
I0122 15:51:45.280530   35788 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
level=WARN msg="upgrade failed" name=consul error="conflict occurred while applying object /gatewayclasses.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /gateways.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /grpcroutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /httproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /referencegrants.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /tcproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /tlsroutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /udproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions"
I0122 15:52:08.145041   35788 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
level=WARN msg="Rollback \"consul\" failed: conflict occurred while applying object /gatewayclasses.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /gateways.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /grpcroutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /httproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /referencegrants.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /tcproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /tlsroutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions && conflict occurred while applying object /udproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with \"kubectl\":\n- .metadata.annotations.api-approved.kubernetes.io\n- .metadata.annotations.gateway.networking.k8s.io/bundle-version\n- .spec.versions"
Error: UPGRADE FAILED: an error occurred while rolling back the release. original upgrade error: conflict occurred while applying object /gatewayclasses.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /gateways.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /grpcroutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /httproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /referencegrants.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /tcproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /tlsroutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /udproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions: conflict occurred while applying object /gatewayclasses.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /gateways.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /grpcroutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /httproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /referencegrants.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /tcproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /tlsroutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions && conflict occurred while applying object /udproutes.gateway.networking.k8s.io apiextensions.k8s.io/v1, Kind=CustomResourceDefinition: Apply failed with 3 conflicts: conflicts with "kubectl":
- .metadata.annotations.api-approved.kubernetes.io
- .metadata.annotations.gateway.networking.k8s.io/bundle-version
- .spec.versions
connectInject:
  enabled: true
  apiGateway:
    #enabled: true
   #manageCRDs: false
    manageExternalCRDS: false
    managedGatewayClass:
      enabled: true
      name: consul
      serviceType: LoadBalancer
      annotations: |
        lbipam.cilium.io/ips: "10.19.143.74"
        service.cilium.io/global: "true"
      # REQUIRED: Label for the Cilium IP Pool selector
      labels:
          io.cilium/lb-ipam-ips: "true"
  default: true
  k8sAllowNamespaces: ["cattle-system","kube-system","consul","infra-system"]
  tls:
    enabled: true


2026-01-22T16:05:03.247Z [INFO]  consul-server-connection-manager.consul-server-connection-manager: trying to connect to a Consul se ││ 2026-01-22T16:05:03.346Z [INFO]  consul-server-connection-manager.consul-server-connection-manager: discovered Consul servers: addre │
│ 2026-01-22T16:05:03.346Z [INFO]  consul-server-connection-manager.consul-server-connection-manager: current prioritized list of know ││ 2026-01-22T16:05:03.458Z [INFO]  consul-server-connection-manager.consul-server-connection-manager: ACL auth method login succeeded: │
│ 2026-01-22T16:05:03.459Z [INFO]  consul-server-connection-manager.consul-server-connection-manager: connected to Consul server: addr ││ 2026-01-22T16:05:03.460Z [INFO]  consul-server-connection-manager.consul-server-connection-manager: updated known Consul servers fro │
│ 2026-01-22T16:05:03.462Z    INFO    setup    Config file present and deserialized    {"file": "/consul/config/config.json", "config" ││ 2026-01-22T16:05:03.466Z    ERROR    setup    unable to register field indexes    {"error": "failed to get API group resources: unab │
│ github.com/hashicorp/consul-k8s/control-plane/subcommand/inject-connect.(*Command).configureControllers                              ││     /home/runner/work/consul-k8s/consul-k8s/control-plane/subcommand/inject-connect/v1controllers.go:110                             │
│ github.com/hashicorp/consul-k8s/control-plane/subcommand/inject-connect.(*Command).Run                                               ││     /home/runner/work/consul-k8s/consul-k8s/control-plane/subcommand/inject-connect/command.go:420                                   │
│ github.com/mitchellh/cli.(*CLI).Run                                                                                                  ││     /home/runner/go/pkg/mod/github.com/mitchellh/cli@v1.1.5/cli.go:262                                                               │
│ main.main                                                                                                                            ││     /home/runner/work/consul-k8s/consul-k8s/control-plane/main.go:21                                                                 │
│ runtime.main                                                                                                                         ││     /opt/hostedtoolcache/go/1.25.5/x64/src/runtime/proc.go:285                                                                       │
│ 2026-01-22T16:05:03.466Z    ERROR    setup    could not configure controllers: failed to get API group resources: unable to retrieve ││ github.com/hashicorp/consul-k8s/control-plane/subcommand/inject-connect.(*Command).Run                                               │
│     /home/runner/work/consul-k8s/consul-k8s/control-plane/subcommand/inject-connect/command.go:422                                   ││ github.com/mitchellh/cli.(*CLI).Run                                                                                                  │
│     /home/runner/go/pkg/mod/github.com/mitchellh/cli@v1.1.5/cli.go:262                                                               │
│ main.main                                                                                                                            │
│     /home/runner/work/consul-k8s/consul-k8s/control-plane/main.go:21                                                                 │
│ runtime.main                                                                                                                         │
│     /opt/hostedtoolcache/go/1.25.5/x64/src/runtime/proc.go:285                                                                       │
│ 2026-01-22T16:05:03.466Z [INFO]  consul-server-connection-manager.consul-server-connection-manager: stopping                         │
│ 2026-01-22T16:05:03.470Z [INFO]  consul-server-connection-manager.consul-server-connection-manager: ACL auth method logout succeeded │
│ stream closed: EOF for consul/cons
