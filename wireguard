Perfect ‚Äî let‚Äôs go all-in and concrete. Below is a production-ready, copy/paste-able path that works with Talos + Omni + Submariner, enforces hub‚Üíspoke only, and avoids all the traps you hit.

I‚Äôll give you everything you listed, in the right order.

‚úÖ FINAL, WORKING ARCHITECTURE (HUB ‚Üí SPOKES ONLY)

Goal

Hub can see all spokes

Spokes can reach only the hub API (never each other)

No Omni API proxying

No shared Kubernetes API

No PodCIDR changes

No LBs per cluster

WireGuard only for bootstrap/control-plane traffic

1Ô∏è‚É£ Exact Omni MachineConfigPatch YAML (READY TO USE)

We‚Äôll create two patches:

One for hub

One for spokes

These are Talos machine patches, delivered via Omni.

üîë Step 0 ‚Äî Generate WireGuard keys (once, offline)

On your workstation:

wg genkey | tee hub.key | wg pubkey > hub.pub
wg genkey | tee spoke.key | wg pubkey > spoke.pub


Keep:

hub.key / hub.pub

spoke.key / spoke.pub

üü¶ Hub MachineConfigPatch (Omni)

Apply to hub control-plane nodes only

machine:
  network:
    interfaces:
      - interface: wg0
        addresses:
          - 10.250.0.1/32
        wireguard:
          privateKey: <HUB_PRIVATE_KEY>
          listenPort: 51820
          peers:
            - publicKey: <SPOKE_PUBLIC_KEY>
              allowedIPs:
                - 10.250.0.2/32


üìå Notes:

/32 = no routing beyond what we allow

No PodCIDR exposure

No node-to-node mesh

üü© Spoke MachineConfigPatch (Omni)

Apply to each spoke control-plane node

machine:
  network:
    interfaces:
      - interface: wg0
        addresses:
          - 10.250.0.2/32
        wireguard:
          privateKey: <SPOKE_PRIVATE_KEY>
          peers:
            - publicKey: <HUB_PUBLIC_KEY>
              endpoint: <HUB_NODE_IP>:51820
              allowedIPs:
                - <HUB_NODE_IP>/32


üìå This allows:

Spoke ‚Üí Hub API only

Nothing else

üß† Omni best practice (100 clusters)

Create one patch per role:

wg-hub-cp

wg-spoke-cp

Reuse the same hub key

Use per-spoke keys if you want zero trust (recommended at scale)

2Ô∏è‚É£ HARD BLOCK spoke ‚Üî spoke (iptables on Talos)

Talos supports node firewall rules.

Add this block to spoke patch:

machine:
  network:
    firewall:
      rules:
        - action: drop
          direction: ingress
          protocol: all
          source:
            subnet: 10.250.0.0/24
          except:
            subnet: 10.250.0.1/32


‚úÖ Result:

Spoke cannot talk to any other spoke

Only hub IP allowed

Even WireGuard packets are filtered

This is stronger than Kubernetes NetworkPolicy.

3Ô∏è‚É£ Validate BEFORE Submariner (MANDATORY)

From your workstation:

talosctl exec -n <spoke-cp-ip> -- \
  curl -k https://<hub-node-ip>:6443/version


Expected:

{
  "gitVersion": "v1.xx.x"
}


‚ùå If this fails ‚Üí STOP
‚úÖ If this works ‚Üí Submariner will work

4Ô∏è‚É£ Submariner ‚Äî THE CORRECT WAY (NO OMNI API)
On the HUB

Regenerate broker info using the real API:

subctl deploy-broker \
  --kubeconfig hub.kubeconfig


Confirm broker URL:

kubectl -n submariner-k8s-broker get secret broker-info -o jsonpath='{.data.broker}'


Must point to:

https://<hub-node-ip>:6443

On EACH SPOKE
subctl join \
  --kubeconfig spoke.kubeconfig \
  broker-info.subm


This works because:

WireGuard makes hub API reachable

TLS SAN matches

SA token is valid

No Omni involved

5Ô∏è‚É£ OPTIONAL ‚Äî Remove WireGuard AFTER JOIN (Safe)

Once Submariner tunnels are up:

Option A ‚Äî Keep WireGuard (recommended)

Used only for API

Minimal attack surface

No routing

Option B ‚Äî Remove WireGuard

In Omni:

Remove the MachineConfigPatch

Reboot control-plane nodes

Submariner tunnels stay up.

6Ô∏è‚É£ Why NOT Cilium ClusterMesh NAT here (comparison)
Feature	WireGuard + Submariner	Cilium ClusterMesh NAT
Needs PodCIDR changes	‚ùå	‚úÖ
Needs API reachability	‚úÖ (once)	‚ùå
Hub-only visibility	‚úÖ	‚ùå
Risk of lateral traffic	‚ùå	‚ö†Ô∏è
Omni compatibility	‚úÖ	‚ö†Ô∏è
Operational complexity	Low	High

Verdict:
ClusterMesh is great for flat mesh.
You want hub-and-spoke ‚Üí Submariner wins.

7Ô∏è‚É£ Why Omni cannot solve this alone (final truth)

Omni is not a Kubernetes API proxy

It cannot accept SA tokens cross-cluster

cluster.controlPlane.endpoint is correctly immutable

Any solution pretending otherwise will break in prod

Your WireGuard + real API approach is:
‚úÖ CNCF-aligned
‚úÖ Secure
‚úÖ Scalable
‚úÖ Boring (in a good way)

If you want next, I can:

Give you a per-cluster WireGuard key rotation strategy

Show Omni labels + patches for auto-enrollment

Provide a Submariner health validation checklist

Draw the exact packet flow (who can talk to whom)



wget -O- http://10.250.0.1:6443         # hangs (no response)
wget -O- http://10.19.143.66:6443       # 400 Bad Request (HTTP to HTTPS)
wget -O- https://10.19.143.66:6443      # 401 Unauthorized (expected for kube-apiserver)
telnet 10.19.143.66 6443                # connects, then server closes (also ok)
ip route                                # shows only CNI default route

--------------------------------------------------------------------------------------------------------------------

-----------------------------------------$ kubectl apply -f  broke_job.yaml
job.batch/deploy-submariner-broker created

PAA3LIS@LIS-C-002L2 MINGW64 ~
$  kubectl -n submariner-k8s-broker get pods
NAME                             READY   STATUS    RESTARTS   AGE
deploy-submariner-broker-pbjbz   2/2     Running   0          4s

PAA3LIS@LIS-C-002L2 MINGW64 ~
$  kubectl -n submariner-k8s-broker get pods
NAME                             READY   STATUS   RESTARTS   AGE
deploy-submariner-broker-8ll2q   0/2     Error    0          31s
deploy-submariner-broker-pbjbz   0/2     Error    0          56s

PAA3LIS@LIS-C-002L2 MINGW64 ~
$ kubectl -n submariner-k8s-broker describe pod deploy-submariner-broker-8ll2q
Name:             deploy-submariner-broker-8ll2q
Namespace:        submariner-k8s-broker
Priority:         0
Service Account:  submariner-broker-installer
Node:             klusterx-worker-infra-04/10.19.143.70
Start Time:       Sat, 31 Jan 2026 21:09:33 +0000
Labels:           batch.kubernetes.io/controller-uid=8e30d3d3-81f9-4690-a32c-500999268064
                  batch.kubernetes.io/job-name=deploy-submariner-broker
                  controller-uid=8e30d3d3-81f9-4690-a32c-500999268064
                  job-name=deploy-submariner-broker
Annotations:      <none>
Status:           Failed
IP:               10.244.5.99
IPs:
  IP:           10.244.5.99
Controlled By:  Job/deploy-submariner-broker
Init Containers:
  write-kubeconfig:
    Container ID:  containerd://54de99a8a381b1fefeea42acfbdce2e01535fe70588755db6367827622b5aecf
    Image:         busybox:1.36
    Image ID:      docker.io/library/busybox@sha256:851281100cc5f93d8a8f8e1a8976a57ec40a9bc9edd66ad3a621e4aa63326915
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
    Args:
      set -eu
      SVC_HOST="${KUBERNETES_SERVICE_HOST:-10.10.143.66}"
      SVC_PORT="${KUBERNETES_SERVICE_PORT:-443}"
      TOKEN="$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)"
      CA_PATH="/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
      CA_B64="$(base64 "$CA_PATH" | tr -d '\n')"
      mkdir -p /work
      printf 'apiVersion: v1\n'                                   >  /work/kubeconfig
      printf 'kind: Config\n'                                     >> /work/kubeconfig
      printf 'clusters:\n'                                        >> /work/kubeconfig
      printf '- name: incluster\n'                                >> /work/kubeconfig
      printf '  cluster:\n'                                       >> /work/kubeconfig
      printf '    server: https://%s:%s\n' "$SVC_HOST" "$SVC_PORT" >> /work/kubeconfig
      printf '    certificate-authority-data: %s\n' "$CA_B64"     >> /work/kubeconfig
      printf 'contexts:\n'                                        >> /work/kubeconfig
      printf '- name: incluster\n'                                >> /work/kubeconfig
      printf '  context:\n'                                       >> /work/kubeconfig
      printf '    cluster: incluster\n'                           >> /work/kubeconfig
      printf '    user: sa\n'                                     >> /work/kubeconfig
      printf 'current-context: incluster\n'                       >> /work/kubeconfig
      printf 'users:\n'                                           >> /work/kubeconfig
      printf '- name: sa\n'                                       >> /work/kubeconfig
      printf '  user:\n'                                          >> /work/kubeconfig
      printf '    token: %s\n' "$TOKEN"                           >> /work/kubeconfig
      echo "Wrote kubeconfig at /work/kubeconfig"

    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 31 Jan 2026 21:09:33 +0000
      Finished:     Sat, 31 Jan 2026 21:09:33 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-dn7xk (ro)
      /work from work (rw)
Containers:
  subctl:
    Container ID:  containerd://fa012e79539b6519caa21191a0365894476e0addbf597b1402b27be726f9d00c
    Image:         quay.io/submariner/subctl:0.22.0
    Image ID:      quay.io/submariner/subctl@sha256:3f78777149921cacee8a2200f8e39113f176c1637160b4ba02bbe704e9c4372f
    Port:          <none>
    Host Port:     <none>
    Command:
      subctl
    Args:
      deploy-broker
      --kubeconfig
      /work/kubeconfig
      --namespace
      submariner-k8s-broker
      --broker-url
      https://10.19.143.66:443
      --globalnet
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Sat, 31 Jan 2026 21:09:34 +0000
      Finished:     Sat, 31 Jan 2026 21:09:47 +0000
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-dn7xk (ro)
      /work from work (rw)
  secret-writer:
    Container ID:  containerd://5404eaaba1db53ff216c040c630a9c2e4a16afe5b73ed04b65535b1f66129760
    Image:         curlimages/curl:8.5.0
    Image ID:      docker.io/curlimages/curl@sha256:08e466006f0860e54fc299378de998935333e0e130a15f6f98482e9f8dab3058
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
    Args:
      set -eu
      NS="submariner-k8s-broker"
      API="https://10.19.143.66:443"
      TOKEN="$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)"
      CACERT="/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"

      # wait for subctl to generate file in /work
      for i in $(seq 1 120); do
        [ -s /work/broker-info.subm ] && break
        sleep 1
      done
      [ -s /work/broker-info.subm ] || { echo "broker-info.subm not found"; exit 1; }

      FILE_B64="$(base64 /work/broker-info.subm | tr -d '\n')"

      cat > /work/secret.json <<EOF
      {
        "apiVersion": "v1",
        "kind": "Secret",
        "metadata": {
          "name": "broker-info",
          "namespace": "${NS}"
        },
        "type": "Opaque",
        "data": {
          "broker-info.subm": "${FILE_B64}"
        }
      }
      EOF

      # Upsert logic: GET; if 404 ‚Üí POST, else ‚Üí PUT
      HTTP_CODE="$(curl -skw '%{http_code}' -o /dev/null \
        -H "Authorization: Bearer ${TOKEN}" \
        --cacert "${CACERT}" \
        "${API}/api/v1/namespaces/${NS}/secrets/broker-info")"

      if [ "${HTTP_CODE}" = "404" ]; then
        echo "Creating Secret broker-info"
        curl -sk \
          -H "Authorization: Bearer ${TOKEN}" \
          -H "Content-Type: application/json" \
          --cacert "${CACERT}" \
          -X POST \
          -d @/work/secret.json \
          "${API}/api/v1/namespaces/${NS}/secrets"
      else
        echo "Updating Secret broker-info"
        curl -sk \
          -H "Authorization: Bearer ${TOKEN}" \
          -H "Content-Type: application/json" \
          --cacert "${CACERT}" \
          -X PUT \
          -d @/work/secret.json \
          "${API}/api/v1/namespaces/${NS}/secrets/broker-info"
      fi

      echo "Secret ${NS}/broker-info upserted."

    State:          Terminated
      Reason:       Error
      Exit Code:    7
      Started:      Sat, 31 Jan 2026 21:09:34 +0000
      Finished:     Sat, 31 Jan 2026 21:09:47 +0000
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-dn7xk (ro)
      /work from work (rw)
Conditions:
  Type                        Status
  PodReadyToStartContainers   False
  Initialized                 True
  Ready                       False
  ContainersReady             False
  PodScheduled                True
Volumes:
  work:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
  kube-api-access-dn7xk:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    Optional:                false
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  54s   default-scheduler  Successfully assigned submariner-k8s-broker/deploy-submariner-broker-8ll2q to klusterx-worker-infra-04
  Normal  Pulled     55s   kubelet            Container image "busybox:1.36" already present on machine
  Normal  Created    55s   kubelet            Created container: write-kubeconfig
  Normal  Started    55s   kubelet            Started container write-kubeconfig
  Normal  Pulled     54s   kubelet            Container image "quay.io/submariner/subctl:0.22.0" already present on machine
  Normal  Created    54s   kubelet            Created container: subctl
  Normal  Started    54s   kubelet            Started container subctl
  Normal  Pulled     54s   kubelet            Container image "curlimages/curl:8.5.0" already present on machine
  Normal  Created    54s   kubelet            Created container: secret-writer
  Normal  Started    54s   kubelet            Started container secret-writer

PAA3LIS@LIS-C-002L2 MINGW64 ~
$ cat broke_job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: deploy-submariner-broker
  namespace: submariner-k8s-broker
spec:
  backoffLimit: 1
  template:
    spec:
      restartPolicy: Never
      serviceAccountName: submariner-broker-installer

      securityContext:
        runAsUser: 0
        runAsGroup: 0

      volumes:
      - name: work
        emptyDir: {}

      initContainers:
      - name: write-kubeconfig
        image: busybox:1.36
        volumeMounts:
        - name: work
          mountPath: /work
        command: ["sh", "-c"]
        args:
        - |
          set -eu
          SVC_HOST="${KUBERNETES_SERVICE_HOST:-10.10.143.66}"
          SVC_PORT="${KUBERNETES_SERVICE_PORT:-443}"
          TOKEN="$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)"
          CA_PATH="/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
          CA_B64="$(base64 "$CA_PATH" | tr -d '\n')"
          mkdir -p /work
          printf 'apiVersion: v1\n'                                   >  /work/kubeconfig
          printf 'kind: Config\n'                                     >> /work/kubeconfig
          printf 'clusters:\n'                                        >> /work/kubeconfig
          printf '- name: incluster\n'                                >> /work/kubeconfig
          printf '  cluster:\n'                                       >> /work/kubeconfig
          printf '    server: https://%s:%s\n' "$SVC_HOST" "$SVC_PORT" >> /work/kubeconfig
          printf '    certificate-authority-data: %s\n' "$CA_B64"     >> /work/kubeconfig
          printf 'contexts:\n'                                        >> /work/kubeconfig
          printf '- name: incluster\n'                                >> /work/kubeconfig
          printf '  context:\n'                                       >> /work/kubeconfig
          printf '    cluster: incluster\n'                           >> /work/kubeconfig
          printf '    user: sa\n'                                     >> /work/kubeconfig
          printf 'current-context: incluster\n'                       >> /work/kubeconfig
          printf 'users:\n'                                           >> /work/kubeconfig
          printf '- name: sa\n'                                       >> /work/kubeconfig
          printf '  user:\n'                                          >> /work/kubeconfig
          printf '    token: %s\n' "$TOKEN"                           >> /work/kubeconfig
          echo "Wrote kubeconfig at /work/kubeconfig"

      containers:
      - name: subctl
        image: quay.io/submariner/subctl:0.22.0
        imagePullPolicy: IfNotPresent
        workingDir: /work
        volumeMounts:
        - name: work
          mountPath: /work
        command: ["subctl"]
        args:
          - deploy-broker
          - --kubeconfig
          - /work/kubeconfig
          - --namespace
          - submariner-k8s-broker
          - --broker-url
          - https://10.19.143.66:443
          # On 0.22, defaults install both components; add if you want explicitness:
          # - --components
          # - service-discovery,connectivity
          # Keep ONLY if you enabled Globalnet intentionally:
          - --globalnet
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]

      - name: secret-writer
        image: curlimages/curl:8.5.0   # <-- has /bin/sh and curl
        volumeMounts:
        - name: work
          mountPath: /work
        command: ["sh","-c"]
        args:
        - |
          set -eu
          NS="submariner-k8s-broker"
          API="https://10.19.143.66:443"
          TOKEN="$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)"
          CACERT="/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"

          # wait for subctl to generate file in /work
          for i in $(seq 1 120); do
            [ -s /work/broker-info.subm ] && break
            sleep 1
          done
          [ -s /work/broker-info.subm ] || { echo "broker-info.subm not found"; exit 1; }

          FILE_B64="$(base64 /work/broker-info.subm | tr -d '\n')"

          cat > /work/secret.json <<EOF
          {
            "apiVersion": "v1",
            "kind": "Secret",
            "metadata": {
              "name": "broker-info",
              "namespace": "${NS}"
            },
            "type": "Opaque",
            "data": {
              "broker-info.subm": "${FILE_B64}"
            }
          }
          EOF

          # Upsert logic: GET; if 404 ‚Üí POST, else ‚Üí PUT
          HTTP_CODE="$(curl -skw '%{http_code}' -o /dev/null \
            -H "Authorization: Bearer ${TOKEN}" \
            --cacert "${CACERT}" \
            "${API}/api/v1/namespaces/${NS}/secrets/broker-info")"

          if [ "${HTTP_CODE}" = "404" ]; then
            echo "Creating Secret broker-info"
            curl -sk \
              -H "Authorization: Bearer ${TOKEN}" \
              -H "Content-Type: application/json" \
              --cacert "${CACERT}" \
              -X POST \
              -d @/work/secret.json \
              "${API}/api/v1/namespaces/${NS}/secrets"
          else
            echo "Updating Secret broker-info"
            curl -sk \
              -H "Authorization: Bearer ${TOKEN}" \
              -H "Content-Type: application/json" \
              --cacert "${CACERT}" \
              -X PUT \
              -d @/work/secret.json \
              "${API}/api/v1/namespaces/${NS}/secrets/broker-info"
          fi

          echo "Secret ${NS}/broker-info upserted."

PAA3LIS@LIS-C-002L2 MINGW64 ~
$  kubectl -n submariner-k8s-broker get pods
NAME                             READY   STATUS   RESTARTS   AGE
deploy-submariner-broker-8ll2q   0/2     Error    0          2m28s
deploy-submariner-broker-pbjbz   0/2     Error    0          2m53s

PAA3LIS@LIS-C-002L2 MINGW64 ~
$ kubectl -n submariner-k8s-broker logs deploy-submariner-broker-8ll2q
Defaulted container "subctl" out of: subctl, secret-writer, write-kubeconfig (init)
 ‚Ä¢ Setting up broker RBAC  ...
 ‚úì Setting up broker RBAC
 ‚Ä¢ Deploying the Submariner operator  ...
 ‚úì Deploying the Submariner operator
 ‚Ä¢ Deploying the broker  ...
 ‚úì Deploying the broker
 ‚Ä¢ Saving broker info to file "broker-info.subm"  ...
 ‚úì Saving broker info to file "broker-info.subm"

PAA3LIS@LIS-C-002L2 MINGW64 ~
$ kubectl -n submariner-k8s-broker logs deploy-submariner-broker-pbjbz
Defaulted container "subctl" out of: subctl, secret-writer, write-kubeconfig (init)
 ‚Ä¢ Setting up broker RBAC  ...
 ‚úì Setting up broker RBAC
 ‚Ä¢ Deploying the Submariner operator  ...
 ‚úì Deploying the Submariner operator
 ‚Ä¢ Deploying the broker  ...
 ‚úì Deploying the broker
 ‚Ä¢ Saving broker info to file "broker-info.subm"  ...
 ‚úì Saving broker info to file "broker-info.subm"

-------------------------------------------------------------------
-----------------------------------------------------------------


  subctl join broker-info.subm \
  --clusterid "mas-qa" \
  --cable-driver wireguard \
  --natt=true \
  --clustercidr "10.244.0.0/16" \
  --servicecidr "10.96.0.0/12" \
  --globalnet-cidr "242.0.2.0/24"
 ‚úì broker-info.subm indicates broker is at https://10.19.143.66:6443
 ‚Ä¢ Discovering network details  ...
 ‚úì Discovering network details
        Network plugin:  generic
        Service CIDRs:   [10.96.0.0/12]
        Cluster CIDRs:   [10.244.0.0/16]
 ‚Ä¢ Retrieving the gateway nodes  ...
   There are 1 node(s) labeled as gateways:
    - klusterx-worker-mas-qa-01
 ‚úì Retrieving the gateway nodes
 ‚Ä¢ Gathering relevant information from Broker  ...
 ‚úó Gathering relevant information from Broker
 ‚úó Error retrieving broker admin config: Get "https://10.19.143.66:6443/apis/submariner.io/v1/namespaces/submariner-k8s-broker/clusters": Bad Gateway

subctl version: v0.22.0
---------------------------------------------------


NAME          STATUS     COMPLETIONS   DURATION   AGE
subctl-join   Complete   1/1           24s        45s

PAA3LIS@LIS-C-002L2 MINGW64 ~
$ kubectl -n submariner-operator get pod
NAME                                             READY   STATUS                 RESTARTS   AGE
subctl-join-ldjzx                                0/1     Completed              0          52s
submariner-gateway-g425b                         0/1     CreateContainerError   0          31s
submariner-globalnet-hvr57                       1/1     Running                0          31s
submariner-lighthouse-agent-6d8bb8975f-gc8gj     1/1     Running                0          31s
submariner-lighthouse-coredns-74db8b9f9f-44pns   1/1     Running                0          31s
submariner-lighthouse-coredns-74db8b9f9f-6mzxv   1/1     Running                0          30s
submariner-metrics-proxy-fch46                   2/2     Running                0          31s
submariner-operator-75bfb7668c-hncnp             1/1     Running                0          41s
submariner-routeagent-9vws9                      1/1     Running                0          31s
submariner-routeagent-s9h96                      1/1     Running                0          31s
submariner-routeagent-x668h                      1/1     Running                0          31s

PAA3LIS@LIS-C-002L2 MINGW64 ~
$  for p in $(kubectl -n submariner-operator get pods -l job-name=subctl-join -o name); do   echo "===== LOGS for $p =====";   kubectl -n submariner-operator logs "$p" --previous || kubectl -n submariner-operator logs "$p"; done
===== LOGS for pod/subctl-join-ldjzx =====
Defaulted container "subctl" out of: subctl, make-kubeconfig (init)
Error from server (BadRequest): previous terminated container "subctl" in pod "subctl-join-ldjzx" not found
Defaulted container "subctl" out of: subctl, make-kubeconfig (init)
 ‚úì /broker/broker-info.subm indicates broker is at https://10.19.143.66:6443
 ‚Ä¢ Discovering network details  ...
 ‚úì Discovering network details
 ‚Ä¢ Retrieving the gateway nodes  ...
        Network plugin:  generic
        Service CIDRs:   [10.96.0.0/12]
        Cluster CIDRs:   [10.244.0.0/16]
   There are 1 node(s) labeled as gateways:
    - klusterx-worker-mas-qa-01
 ‚úì Retrieving the gateway nodes
 ‚Ä¢ Gathering relevant information from Broker  ...
 ‚úì Gathering relevant information from Broker
 ‚Ä¢ Retrieving Globalnet information from the Broker  ...
 ‚úì Retrieving Globalnet information from the Broker
 ‚Ä¢ Validating Globalnet configuration  ...
 ‚úì Validating Globalnet configuration
 ‚Ä¢ Assigning Globalnet IPs  ...
 ‚úì Assigning Globalnet IPs
 ‚úì Using specified global CIDR 242.0.2.0/24
 ‚Ä¢ Updating the Globalnet information on the Broker  ...
 ‚úì Updating the Globalnet information on the Broker
 ‚Ä¢ Retrieving ClustersetIP information from the Broker  ...
 ‚úì Retrieving ClustersetIP information from the Broker
 ‚Ä¢ Validating ClustersetIP configuration  ...
 ‚úì Validating ClustersetIP configuration
 ‚Ä¢ Assigning ClustersetIP IPs  ...
 ‚úì Assigning ClustersetIP IPs
 ‚úì Allocated clustersetip CIDR 243.0.0.0/20
 ‚Ä¢ Updating the ClustersetIP information on the Broker  ...
 ‚úì Updating the ClustersetIP information on the Broker
 ‚Ä¢ Deploying the Submariner operator  ...
 ‚úì Deploying the Submariner operator
 ‚úì Created operator service account and role
 ‚úì Created submariner service account and role
 ‚úì Created lighthouse service account and role
 ‚úì Deployed the operator successfully
 ‚Ä¢ Creating SA for cluster  ...
 ‚úì Creating SA for cluster
 ‚Ä¢ Connecting to Broker  ...
 ‚úì Connecting to Broker
 ‚Ä¢ Deploying submariner  ...
 ‚úì Deploying submariner
 ‚úì Submariner is up and running
-----------------------------------------------------------------------

Events:
  Type     Reason     Age                    From               Message
  ----     ------     ----                   ----               -------
  Normal   Scheduled  7m28s                  default-scheduler  Successfully assigned submariner-operator/submariner-gateway-g425b to klusterx-worker-mas-qa-01
  Normal   Pulling    7m27s                  kubelet            Pulling image "quay.io/submariner/submariner-gateway:release-0.22"
  Normal   Pulled     7m9s                   kubelet            Successfully pulled image "quay.io/submariner/submariner-gateway:release-0.22" in 18.386s (18.386s including waiting). Image size: 76252382 bytes.
  Normal   Created    7m9s                   kubelet            Created container: submariner-gateway-init
  Normal   Started    7m9s                   kubelet            Started container submariner-gateway-init
  Normal   Pulled     7m8s                   kubelet            Successfully pulled image "quay.io/submariner/submariner-gateway:release-0.22" in 402ms (402ms including waiting). Image size: 76252382 bytes.
  Warning  Failed     7m8s                   kubelet            Error: failed to generate container "f42713d9afd03f31cf683f312a7359e3a2e43073100c7dcee3531f10e044a7be" spec: failed to apply OCI options: failed to mkdir "/etc/ipsec.d": mkdir /etc/ipsec.d: read-only file system
  Normal   Pulled     7m7s                   kubelet            Successfully pulled image "quay.io/submariner/submariner-gateway:release-0.22" in 359ms (359ms including waiting). Image size: 76252382 bytes.
  Warning  Failed     7m7s                   kubelet            Error: failed to generate container "74dd89295b274f4956a77ab7c819c424558ebabada0dc0ec0c9d4b05d8da6f01" spec: failed to apply OCI options: failed to mkdir "/etc/ipsec.d": mkdir /etc/ipsec.d: read-only file system
  Warning  Failed     6m52s                  kubelet            Error: failed to generate container "10f2e7d277dfcf5a782b7fbe138f40070723baa395ac25b30464170de8204ac6" spec: failed to apply OCI options: failed to mkdir "/etc/ipsec.d": mkdir /etc/ipsec.d: read-only file system
  Normal   Pulled     6m52s                  kubelet            Successfully pulled image "quay.io/submariner/submariner-gateway:release-0.22" in 351ms (351ms including waiting). Image size: 76252382 bytes.
  Normal   Pulled     6m40s                  kubelet            Successfully pulled image "quay.io/submariner/submariner-gateway:release-0.22" in 350ms (350ms including waiting). Image size: 76252382 bytes.
  Warning  Failed     6m40s                  kubelet            Error: failed to generate container "c7961b8383d555fcfda90e7b23acfdbbef3262b71d8a8110f1af738d52d1a60c" spec: failed to apply OCI options: failed to mkdir "/etc/ipsec.d": mkdir /etc/ipsec.d: read-only file system
  Normal   Pulled     6m27s                  kubelet            Successfully pulled image "quay.io/submariner/submariner-gateway:release-0.22" in 485ms (485ms including waiting). Image size: 76252382 bytes.
  Warning  Failed     6m27s                  kubelet            Error: failed to generate container "1bb2d3426ce949e69492b9a087d99c7e6ca3af737568f47322d2a40f529041d8" spec: failed to apply OCI options: failed to mkdir "/etc/ipsec.d": mkdir /etc/ipsec.d: read-only file system
  Warning  Failed     6m12s                  kubelet            Error: failed to generate container "441642fb2d84ef699c24864ec77f6b28c6f0c2e56e85d9ff71a0de3d6fb8c846" spec: failed to apply OCI options: failed to mkdir "/etc/ipsec.d": mkdir /etc/ipsec.d: read-only file system
  Normal   Pulled     6m12s                  kubelet            Successfully pulled image "quay.io/submariner/submariner-gateway:release-0.22" in 376ms (376ms including waiting). Image size: 76252382 bytes.
  Normal   Pulled     6m1s                   kubelet            Successfully pulled image "quay.io/submariner/submariner-gateway:release-0.22" in 451ms (451ms including waiting). Image size: 76252382 bytes.
  Warning  Failed     6m1s                   kubelet            Error: failed to generate container "57e180c85144c4bd92e008aed96d68320120218b77cd90fce208d1b568f8d215" spec: failed to apply OCI options: failed to mkdir "/etc/ipsec.d": mkdir /etc/ipsec.d: read-only file system
  Normal   Pulled     5m50s                  kubelet            Successfully pulled image "quay.io/submariner/submariner-gateway:release-0.22" in 347ms (347ms including waiting). Image size: 76252382 bytes.
  Warning  Failed     5m50s                  kubelet            Error: failed to generate container "0b7771a324b5256ac545c8ee050dee578703610d4b631d4d8e52d0cb7d9ae504" spec: failed to apply OCI options: failed to mkdir "/etc/ipsec.d": mkdir /etc/ipsec.d: read-only file system
  Warning  Failed     5m36s                  kubelet            Error: failed to generate container "dda88610f6789e1e44a67d807d20451e8afc4834160702e2c887d59299747013" spec: failed to apply OCI options: failed to mkdir "/etc/ipsec.d": mkdir /etc/ipsec.d: read-only file system
  Normal   Pulled     5m21s (x2 over 5m36s)  kubelet            (combined from similar events): Successfully pulled image "quay.io/submariner/submariner-gateway:release-0.22" in 389ms (389ms including waiting). Image size: 76252382 bytes.
  Normal   Pulling    2m12s (x24 over 7m9s)  kubelet            Pulling image "quay.io/submariner/submariner-gateway:release-0.22"
  Warning  Failed     108s (x17 over 5m21s)  kubelet            (combined from similar events): Error: failed to generate container "3397c96d1ce3ebc01b980a32df46aa86ebab3b45320e5aa4996665e8cc00d217" spec: failed to apply OCI options: failed to mkdir "/etc/ipsec.d": mkdir /etc/ipsec.d: read-only file system


