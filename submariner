Perfect ‚Äî this is the right moment to be very explicit and mechanical.
Below is a production-safe, Talos-compatible, OIDC-compatible way to join spokes ‚Üí hub using Submariner OSS, assuming:

‚úÖ Broker already installed in HUB
‚úÖ You are using Talos OS
‚úÖ Omni / OIDC is enabled (humans use OIDC)
‚úÖ Submariner must run in-cluster (not from your laptop)

We‚Äôll do this in clear phases, with exact files and commands.

PHASE 0 ‚Äî What we are building (mental map)

For each SPOKE cluster we will:

Create a ServiceAccount (machine auth)

Create a short-lived token

Build a minimal kubeconfig (NO OIDC)

Store it as a Secret in the HUB

Run a Job in the HUB that executes subctl join

Verify gateways + connectivity

Talos does nothing special here.

PHASE 1 ‚Äî On EACH SPOKE cluster (once per spoke)

These commands are run against the SPOKE cluster API
(from a VM that can reach it, or via Omni exec)

1Ô∏è‚É£ Create namespace
kubectl create namespace submariner-operator

2Ô∏è‚É£ Create ServiceAccount
kubectl -n submariner-operator create serviceaccount submariner-bootstrap

3Ô∏è‚É£ Bind cluster-admin (required by subctl)
# submariner-bootstrap-crb.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: submariner-bootstrap
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: submariner-bootstrap
  namespace: submariner-operator

kubectl apply -f submariner-bootstrap-crb.yaml


‚ö†Ô∏è Yes, cluster-admin is required during install.
You can reduce permissions later.

4Ô∏è‚É£ Generate a token (THIS IS CRITICAL)
kubectl -n submariner-operator create token submariner-bootstrap


You should see something like:

eyJhbGciOiJSUzI1NiIsImtpZCI6...


üëâ Save this token (copy it somewhere safe)

5Ô∏è‚É£ Get the SPOKE API server URL
kubectl config view --raw -o jsonpath='{.clusters[0].cluster.server}'


Example:

https://10.0.0.10:6443

6Ô∏è‚É£ Get the CA certificate (Talos-safe way)

Talos does NOT embed CA in kubeconfig when using OIDC.

Use this instead:

kubectl -n kube-system get configmap kube-root-ca.crt \
  -o jsonpath='{.data.ca\.crt}' > ca.crt


Then base64 it:

base64 -w0 ca.crt


Save the output ‚Äî this is your certificate-authority-data.

7Ô∏è‚É£ Create the SPOKE kubeconfig (FILE 1)

üìÑ spoke1.kubeconfig

apiVersion: v1
kind: Config
clusters:
- name: spoke1
  cluster:
    server: https://<SPOKE_API>:6443
    certificate-authority-data: <BASE64_CA>
contexts:
- name: spoke1
  context:
    cluster: spoke1
    user: submariner-bootstrap
current-context: spoke1
users:
- name: submariner-bootstrap
  user:
    token: <TOKEN_FROM_STEP_4>


‚ùó Replace:

<SPOKE_API>

<BASE64_CA>

<TOKEN_FROM_STEP_4>

8Ô∏è‚É£ Validate kubeconfig (VERY IMPORTANT)
kubectl --kubeconfig=spoke1.kubeconfig get nodes


If this fails ‚Üí STOP and fix it.
Submariner will NOT work if this fails.

PHASE 2 ‚Äî Move kubeconfig into the HUB cluster

These commands run against the HUB cluster

9Ô∏è‚É£ Create Secret in HUB
kubectl -n submariner-k8s-broker create secret generic spoke1-kubeconfig \
  --from-file=kubeconfig=spoke1.kubeconfig


Verify:

kubectl -n submariner-k8s-broker get secret spoke1-kubeconfig

PHASE 3 ‚Äî Run subctl JOIN as a Job (HUB)

This avoids laptop / OIDC / Talos issues.

üîü Create the JOIN Job (FILE 2)

üìÑ subctl-join-spoke1.yaml

apiVersion: batch/v1
kind: Job
metadata:
  name: subctl-join-spoke1
  namespace: submariner-k8s-broker
spec:
  backoffLimit: 1
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: subctl
        image: quay.io/submariner/subctl:0.19.1
        command:
        - /bin/sh
        - -c
        - |
          subctl join \
            --kubeconfig /spoke/kubeconfig \
            broker-info.subm \
            --clusterid spoke1 \
            --natt=true
        volumeMounts:
        - name: spoke-kubeconfig
          mountPath: /spoke
      volumes:
      - name: spoke-kubeconfig
        secret:
          secretName: spoke1-kubeconfig


--natt=true is REQUIRED because you have overlapping PodCIDRs.

1Ô∏è‚É£1Ô∏è‚É£ Apply the Job
kubectl apply -f subctl-join-spoke1.yaml


Watch logs:

kubectl -n submariner-k8s-broker logs job/subctl-join-spoke1 -f


You want to see:

‚úì Cluster "spoke1" joined successfully

PHASE 4 ‚Äî Verify Submariner is actually working
1Ô∏è‚É£2Ô∏è‚É£ Check gateway nodes (SPOKE)
kubectl get nodes -l submariner.io/gateway=true

1Ô∏è‚É£3Ô∏è‚É£ Check pods
kubectl -n submariner-operator get pods


You should see:

submariner-gateway

submariner-route-agent

submariner-operator

1Ô∏è‚É£4Ô∏è‚É£ Verify connection in HUB
kubectl -n submariner-k8s-broker get clusters

1Ô∏è‚É£5Ô∏è‚É£ Test pod-to-pod connectivity

Create a test pod in HUB and SPOKE:

kubectl run test --image=busybox -it --restart=Never -- sh


From HUB ‚Üí ping SPOKE pod IP.

If this works ‚Üí network fabric is DONE.

PHASE 5 ‚Äî What happens next (important)

Now:

Pods can talk cross-cluster

Services can be resolved

Consul gossip works

Envoy xDS works

MeshGateways become OPTIONAL

Submariner solved L3/L4
Consul solves L7 + service discovery
Used in managed clusters

Compatible with Talos constraints
###################################################


apiVersion: batch/v1
kind: Job
metadata:
  name: subctl-join
  namespace: submariner-operator
spec:
  backoffLimit: 1
  template:
    spec:
      restartPolicy: Never
      serviceAccountName: submariner-bootstrap
      containers:
      - name: subctl
        image: quay.io/submariner/subctl:0.19.1
        command:
        - /bin/sh
        - -c
        - |
          subctl join \
            broker-info.subm \
            --clusterid spoke1 \
            --natt=true \
            --kubeconfig /var/run/secrets/kubernetes.io/serviceaccount/kubeconfig
        volumeMounts:
        - name: broker
          mountPath: /broker
      volumes:
      - name: broker
        secret:
          secretName: broker-info


#############################################################

$ # Fetch logs from all pods for the job
for p in $(kubectl -n submariner-operator get pods -l job-name=subctl-join -o name); do
  echo "===== LOGS for $p ====="
  kubectl -n submariner-operator logs "$p" --previous || kubectl -n submariner-operator logs "$p"
done
===== LOGS for pod/subctl-join-h29zl =====
Error from server (BadRequest): previous terminated container "subctl" in pod "subctl-join-h29zl" not found
 ‚úì /broker/broker-info.subm indicates broker is at https://kube-omni-klusterx.de.bosch.com/
 ‚úó Error retrieving the default configuration: could not obtain the cluster name from kube config: api.Config{Kind:"", APIVersion:"", Preferences:api.Preferences{Colors:false, Extensions:map[string]runtime.Object{}}, Clusters:map[string]*api.Cluster{}, AuthInfos:map[string]*api.AuthInfo{}, Contexts:map[string]*api.Context{}, CurrentContext:"", Extensions:map[string]runtime.Object{}}

subctl version: release-0.19-260d4934ea54

===== LOGS for pod/subctl-join-l87bn =====
Error from server (BadRequest): previous terminated container "subctl" in pod "subctl-join-l87bn" not found
 ‚úì /broker/broker-info.subm indicates broker is at https://kube-omni-klusterx.de.bosch.com/
 ‚úó Error retrieving the default configuration: could not obtain the cluster name from kube config: api.Config{Kind:"", APIVersion:"", Preferences:api.Preferences{Colors:false, Extensions:map[string]runtime.Object{}}, Clusters:map[string]*api.Cluster{}, AuthInfos:map[string]*api.AuthInfo{}, Contexts:map[string]*api.Context{}, CurrentContext:"", Extensions:map[string]runtime.Object{}}

subctl version: release-0.19-260d4934ea54
