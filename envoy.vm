cat envoy.yaml
# envoy-bootstrap.yaml
# Minimal ADS bootstrap to Consul agent gRPC (xDS v3)
 
node:
  id: envoy-edge-01-gw
  cluster: central-primary-infra
 
dynamic_resources:
  lds_config:
    resource_api_version: V3
    ads: {}
  cds_config:
    resource_api_version: V3
    ads: {}
  ads_config:
    api_type: GRPC
    transport_api_version: V3
    grpc_services:
    - envoy_grpc:
        cluster_name: consul_xds
 
static_resources:
  clusters:
  - name: consul_xds
    type: STATIC
    connect_timeout: 5s
    http2_protocol_options: {}
    load_assignment:
      cluster_name: consul_xds
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: 10.19.143.87
                port_value: 8502              # Consul agent gRPC port
#    tls_context:
#      common_tls_context:
#        tls_params:
#          tls_minimum_protocol_version: TLSv1_2
        # If your Consul agent requires mTLS for xDS, you must supply certs or use SDS.
        # In the auto bootstrap, Consul wires SDS; manually you must mount certs here.
 
admin:
  access_log_path: /var/log/envoy/admin_access.log
  address:
    socket_address:
      address: 0.0.0.0
      port_value: 19000



---------------

ailure reason: delayed connect error: Connection refused
Feb 03 17:39:32 klusterx-envoyingress-01 envoy[209697]: [2026-02-03 17:39:32.534][209697][warning][config] [./source/extensions/config_subscription/grpc/grpc_stream.h:226] StreamAggregatedResources gRPC config stream to consul_xds closed since 1015s ago: 14, upstream connect error or disconnect/reset before headers. reset reason: remote connection failure, transport failure reason: delayed connect error: Connection refused
Feb 03 17:39:34 klusterx-envoyingress-01 envoy[209697]: [2026-02-03 17:39:34.476][209697][warning][config] [./source/extensions/config_subscription/grpc/grpc_stream.h:226] StreamAggregatedResources gRPC config stream to consul_xds closed since 1017s ago: 14, upstream connect error or disconnect/reset before headers. reset reason: remote connection failure, transport failure reason: delayed connect error: Connection refused
Feb 03 17:39:59 klusterx-envoyingress-01 envoy[209697]: [2026-02-03 17:39:59.276][209697][warning][config] [./source/extensions/config_subscription/grpc/grpc_stream.h:226] StreamAggregatedResources gRPC config stream to consul_xds closed since 1041s ago: 14, upstream connect error or disconnect/reset before headers. reset reason: remote connection failure, transport failure reason: delayed connect error: Connection refused
Feb 03 17:40:09 klusterx-envoyingress-01 envoy[209697]: [2026-02-03 17:40:09.912][209697][warning][config] [./source/extensions/config_subscription/grpc/grpc_stream.h:226] StreamAggregatedResources gRPC config stream to consul_xds closed since 1052s ago: 14, upstream connect error or disconnect/reset before headers. reset reason: remote connection failure, transport failure reason: delayed connect error: Connection refused
Feb 03 17:40:13 klusterx-envoyingress-01 envoy[209697]: [2026-02-03 17:40:13.456][209697][warning][config] [./source/extensions/config_subscription/grpc/grpc_stream.h:226] StreamAggregatedResources gRPC config stream to consul_xds closed since 1055s ago: 14, upstream connect error or disconnect/reset before headers. reset reason: remote connection failure, transport failure reason: delayed connect error: Connection refused
Feb 03 17:40:26 klusterx-envoyingress-01 envoy[209697]: [2026-02-03 17:40:26.266][209697][warning][config] [./source/extensions/config_subscription/grpc/grpc_stream.h:226] StreamAggregatedResources gRPC config stream to consul_xds closed since 1068s ago: 14, upstream connect error or disconnect/reset before headers. reset reason: remote connection failure, transport failure reason: delayed connect error: Connection refused
Feb 03 17:40:51 klusterx-envoyingress-01 envoy[209697]: [2026-02-03 17:40:51.570][209697][warning][config] [./source/extensions/config_subscription/grpc/grpc_stream.h:226] StreamAggregatedResources gRPC config stream to consul_xds closed since 1094s ago: 14, upstream connect error or disconnect/reset before headers. reset reason: remote connection failure, transport failure reason: delayed connect error: Connection refused

this is not the connect or envoy connect i told him he needs to do envoy connect he says he dint do that 

consul-connect-injector   ClusterIP      10.98.231.216   <none>          443/TCP                                                                            18d
consul-dns                ClusterIP      10.101.163.68   <none>          53/TCP,53/UDP                                                                      18d
consul-expose-servers     LoadBalancer   10.104.65.116   10.19.143.87    8501:30648/TCP,8301:31760/TCP,8300:31104/TCP,8502:32215/TCP,8301:31894/UDP         13d
consul-mesh-gateway       LoadBalancer   10.106.225.33   10.19.143.100   443:30691/TCP                                                                      13d
consul-server             ClusterIP      None            <none>          8501/TCP,8502/TCP,8301/TCP,8301/UDP,8302/TCP,8302/UDP,8300/TCP,8600/TCP,8600/UDP   18d
consul-ui                 ClusterIP      10.98.155.166   <none>          443/TCP                                                                             
kubectl -n consul get pods -o wide
kubectl -n consul exec -it consul-server-0 -- ss -lunp | grep 8301
-----------------------------------


global:
  name: consul
  datacenter: central-primary-infra

  tls:
    enabled: true
    enableAutoEncrypt: true
    httpsOnly: true
  gossipEncryption:
    enabled: true

  acls:
    manageSystemACLs: true
  authMethod:
     enable: true
     name: consul-k8s-component-auth-method
   # bootstrapToken:
   #   secretName: consul-bootstrap-acl-token
   #   secretKey: token

  peering:
    enabled: true

  meshGateway:
    enabled: true


#gatewayAPI:
 #   enabled: false

ui:
  enabled: true

controller:
  enabled: controller
  #gatewayAPI:
   # enabled: false

dataplane:
  enabled: true

server:
  enabled: true
  replicas: 3
  bootstrapExpect: 3

  exposeService:
   enabled: true
   type: LoadBalancer
   annotations: |
        lbipam.cilium.io/ips: "10.19.143.87"
        service.cilium.io/global: "true"
     # REQUIRED: Label for the Cilium IP Pool selector
   labels:
        io.cilium/lb-ipam-ips: "true"


  extraConfig: |
    {
      "acl": {
        "enabled": true,
        "default_policy": "allow",
        "enable_token_persistence": true
      },

       "connect": { "enabled": true },
       "auto_encrypt": { "allow_tls": true }

    }

client:
  enabled: true
  grpc: true
  extraConfig: |
    {
      "verify_incoming": false,
      "verify_outgoing": true,
      "verify_server_hostname": true
    }

connectInject:
  enabled: true
  #apiGateway:
   # enabled: false
   # manageNonStandardCRDs: false
  #  manageExternalCRDs: false
  default: true
  k8sAllowNamespaces: ["cattle-system","kube-system","consul","infra-system","submariner-operator","submariner-k8s-broker"]
  tls:
    enabled: true

syncCatalog:
  enabled: true
  toConsul: true
  toK8S: false
  consulNodeName: "omni-infra"
  k8sAllowNamespaces: ["cattle-system","kube-system","consul","infra-system","submariner-operator","submariner-k8s-broker"]
  k8sDenyNamespaces: ["default"]
  addK8SNamespaceSuffix: false
  tls:
    enabled: true

meshGateway:
  enabled: true
  replicas: 2
  service:
    type: LoadBalancer
    # chart 1.9.x expects a STRING here, not a map
    annotations: |
      service.cilium.io/global: "true"
      lbipam.cilium.io/ips: "10.19.143.100"
      consul.hashicorp.com/connect-inject: "true"
      consul.hashicorp.com/mesh-inject: "true"
    labels:
        io.cilium/lb-ipam-ips: "true"
  hostNetwork: false

extraServices:
  gossip:
    enabled: true
    name: consul-gossip
    type: ClusterIP
    clusterIP: None       # headless â†’ best for gossip
    ports:
      - name: gossip-tcp
        port: 8301
        targetPort: 8301
        protocol: TCP
      - name: gossip-udp
        port: 8301
        targetPort: 8301
        protocol: UDP
-------------------------------------------------------------


datacenter = "central-primary-infra"
node_name  = "envoy-edge-01"
data_dir   = "/opt/consul"
 
client_addr = "0.0.0.0"
 
 
ports {
  http  = 8500
  grpc = 8502          # <--- ESSENCIAL (xDS)
  https = 8501         # se estiver usando HTTPS (ACL/TLS)
}
 
retry_join = ["10.19.143.87"]
 
connect {
  enabled = true
}
 
auto_encrypt = {
  tls = true
}
 
tls {
  defaults {
    ca_file = "/etc/envoy/tls/consul-ca-cert.crt"
    verify_incoming = true
    verify_outgoing = true
    verify_server_hostname = true
  }
 
  internal_rpc {
    verify_server_hostname = true
  }
}

------------------

error with this Feb 03 18:53:01 klusterx-envoyingress-01 consul[210792]: 2026-02-03T18:53:01.934Z [ERROR] agent.auto_config: No servers successfully responded to the auto-encrypt request
Feb 03 18:53:01 klusterx-envoyingress-01 consul[210792]: 2026-02-03T18:53:01.939Z [ERROR] agent.auto_config: AutoEncrypt.Sign RPC failed: addr=10.19.143.87:8300 error="rpcinsecure: er>
Feb 03 18:53:01 klusterx-envoyingress-01 consul[210792]: 2026-02-03T18:53:01.939Z [ERROR] agent.auto_config: No servers successfully responded to the auto-encrypt request
Feb 03 18:53:03 klusterx-envoyingress-01 consul[210792]: 2026-02-03T18:53:03.222Z [ERROR] agent.auto_config: AutoEncrypt.Sign RPC failed: addr=10.19.143.87:8300 error="rpcinsecure: er>
Feb 03 18:53:03 klusterx-envoyingress-01 consul[210792]: 2026-02-03T18:53:03.222Z [ERROR] agent.auto_config: No servers successfully responded to the auto-encrypt request
Feb 03 18:53:05 klusterx-envoyingress-01 consul[210792]: 2026-02-03T18:53:05.273Z [ERROR] agent.auto_config: AutoEncrypt.Sign RPC failed: addr=10.19.143.87:8300 error="rpcinsecure: er>
Feb 03 18:53:05 klusterx-envoyingress-01 consul[210792]: 2026-02-03T18:53:05.273Z [ERROR] agent.auto_config: No servers successfully responded to the auto-encrypt request


  # Exposes the servers' gossip and RPC ports as hostPorts. To enable a client
  # agent outside of the k8s cluster to join the datacenter, you would need to
  # enable `server.exposeGossipAndRPCPorts`, `client.exposeGossipPorts`, and
  # set `server.ports.serflan.port` to a port not being used on the host. Since


---------------

Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:08.036Z [WARN]  agent.router.manager: No servers available
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:08.036Z [ERROR] agent.anti_entropy: failed to sync remote state: error="No known Consul servers"
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:08.603Z [WARN]  agent: (LAN) couldn't join: number_of_nodes=0
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]:   error=
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]:   | 1 error occurred:
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]:   | \t* Failed to join 10.19.143.87:8301: dial tcp 10.19.143.87:8301: connect: no route to host
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]:   |
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]:   
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:08.603Z [WARN]  agent: Join cluster failed, will retry: cluster=LAN retry_interval=30s
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]:   error=
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]:   | 1 error occurred:
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]:   | \t* Failed to join 10.19.143.87:8301: dial tcp 10.19.143.87:8301: connect: no route to host
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]:   |
Feb 04 10:46:08 klusterx-envoyingress-01 consul[3162]:   
Feb 04 10:46:10 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:10.403Z [WARN]  agent.router.manager: No servers available
Feb 04 10:46:11 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:11.173Z [WARN]  agent.router.manager: No servers available
Feb 04 10:46:15 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:15.197Z [WARN]  agent: Check TCP connection failed: check=service:edge-proxy-01-sidecar-proxy:1 error="dial tcp 127.0.0.1:21000: connect: connection refused"
Feb 04 10:46:15 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:15.197Z [WARN]  agent: Check is now critical: check=service:edge-proxy-01-sidecar-proxy:1
Feb 04 10:46:15 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:15.266Z [WARN]  agent.router.manager: No servers available
Feb 04 10:46:15 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:15.640Z [WARN]  agent.router.manager: No servers available
Feb 04 10:46:18 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:18.344Z [WARN]  agent.router.manager: No servers available
Feb 04 10:46:23 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:23.959Z [WARN]  agent.router.manager: No servers available
Feb 04 10:46:25 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:25.197Z [WARN]  agent: Check TCP connection failed: check=service:edge-proxy-01-sidecar-proxy:1 error="dial tcp 127.0.0.1:21000: connect: connection refused"
Feb 04 10:46:25 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:25.197Z [WARN]  agent: Check is now critical: check=service:edge-proxy-01-sidecar-proxy:1
Feb 04 10:46:27 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:27.398Z [WARN]  agent.router.manager: No servers available
Feb 04 10:46:30 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:30.005Z [WARN]  agent.router.manager: No servers available
Feb 04 10:46:33 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:33.222Z [WARN]  agent.router.manager: No servers available
Feb 04 10:46:33 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:33.222Z [ERROR] agent.anti_entropy: failed to sync remote state: error="No known Consul servers"
Feb 04 10:46:35 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:35.198Z [WARN]  agent: Check TCP connection failed: check=service:edge-proxy-01-sidecar-proxy:1 error="dial tcp 127.0.0.1:21000: connect: connection refused"
Feb 04 10:46:35 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:35.198Z [WARN]  agent: Check is now critical: check=service:edge-proxy-01-sidecar-proxy:1
Feb 04 10:46:38 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:38.604Z [INFO]  agent: (LAN) joining: lan_addresses=["10.19.143.87"]
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:41.691Z [WARN]  agent: (LAN) couldn't join: number_of_nodes=0
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]:   error=
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]:   | 1 error occurred:
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]:   | \t* Failed to join 10.19.143.87:8301: dial tcp 10.19.143.87:8301: connect: no route to host
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]:   |
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]:   
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:41.691Z [WARN]  agent: Join cluster failed, will retry: cluster=LAN retry_interval=30s
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]:   error=
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]:   | 1 error occurred:
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]:   | \t* Failed to join 10.19.143.87:8301: dial tcp 10.19.143.87:8301: connect: no route to host
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]:   |
Feb 04 10:46:41 klusterx-envoyingress-01 consul[3162]:   
Feb 04 10:46:44 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:44.256Z [WARN]  agent.router.manager: No servers available
Feb 04 10:46:45 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:45.198Z [WARN]  agent: Check TCP connection failed: check=service:edge-proxy-01-sidecar-proxy:1 error="dial tcp 127.0.0.1:21000: connect: connection refused"
Feb 04 10:46:45 klusterx-envoyingress-01 consul[3162]: 2026-02-04T10:46:45.198Z [WARN]  agent: Check is now critical: check=service:edge-proxy-01-sidecar-proxy:1
lines 11-32/50 57%

note that 
-------------------------------------------------------------------------------------------------------------------------------------------------------

----------------------------------------------------------------------------------------------------------------------------------------------------






datacenter = "central-primary-infra"
node_name  = "envoy-edge-01"
data_dir   = "/opt/consul"

client_addr = "0.0.0.0"


ports {
  http  = 8500
  grpc = 8502          # <--- ESSENCIAL (xDS)
  https = 8501         # se estiver usando HTTPS (ACL/TLS)
}

retry_join = ["10.19.143.87"]

#connect {
#  enabled = true
#}

#auto_encrypt = {
 # tls = true
#}
tls {
  defaults {
    ca_file = "/etc/envoy/tls/consul-ca.pem"
    verify_incoming = false
    verify_outgoing = true
    verify_server_hostname = true
  }

  internal_rpc {
    verify_server_hostname = true
  }
}




root@klusterx-envoyingress-01:/etc/consul.d# cat  logging
Feb 04 14:59:34 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:34.694Z [INFO]  agent.client.memberlist.lan: memberlist: Suspect klusterx-worker-infra-05 has failed, no acks received
Feb 04 14:59:35 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:35.846Z [ERROR] agent.client: RPC failed to server: method=ConfigEntry.ResolveServiceConfig server=10.244.5.248:8300 error="rpc error getting client: failed to get conn: dial tcp <nil>->10.244.5.248:8300: i/o timeout"
Feb 04 14:59:35 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:35.846Z [ERROR] agent.client: RPC failed to server: method=Coordinate.Update server=10.244.5.248:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:35 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:35.846Z [ERROR] agent: Coordinate update error: error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:35 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:35.846Z [ERROR] agent.client: RPC failed to server: method=ConfigEntry.Get server=10.244.5.248:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:35 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:35.846Z [ERROR] agent.client: RPC failed to server: method=ConnectCA.Roots server=10.244.5.248:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:35 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:35.846Z [ERROR] agent.client: RPC failed to server: method=ConfigEntry.List server=10.244.5.248:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:37 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:37.104Z [WARN]  agent: Check TCP connection failed: check=service:edge-proxy-01-sidecar-proxy:1 error="dial tcp 127.0.0.1:21000: connect: connection refused"
Feb 04 14:59:37 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:37.104Z [WARN]  agent: Check is now critical: check=service:edge-proxy-01-sidecar-proxy:1
Feb 04 14:59:41 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:41.381Z [WARN]  agent: [core][Channel #1 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "central-primary-infra-10.244.3.228:8300", ServerName: "consul-server-2", }. Err: connection error: desc = "transport: Error while dialing: dial tcp <nil>->10.244.3.228:8300: i/o timeout"
Feb 04 14:59:42 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:42.695Z [INFO]  agent.client.memberlist.lan: memberlist: Suspect consul-server-0 has failed, no acks received
Feb 04 14:59:42 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:42.761Z [INFO]  agent.client.memberlist.lan: memberlist: Marking consul-server-1 as failed, suspect timeout reached (1 peer confirmations)
Feb 04 14:59:42 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:42.761Z [INFO]  agent.client.serf.lan: serf: EventMemberFailed: consul-server-1 10.244.1.166
Feb 04 14:59:42 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:42.761Z [INFO]  agent.client: removing server: server="consul-server-1 (Addr: tcp/10.244.1.166:8300) (DC: central-primary-infra)"
Feb 04 14:59:42 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:42.999Z [INFO]  agent.client.serf.lan: serf: EventMemberJoin: consul-server-1 10.244.1.166
Feb 04 14:59:42 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:42.999Z [INFO]  agent.client: adding server: server="consul-server-1 (Addr: tcp/10.244.1.166:8300) (DC: central-primary-infra)"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.847Z [ERROR] agent.client: RPC failed to server: method=ConfigEntry.ResolveServiceConfig server=10.244.3.228:8300 error="rpc error getting client: failed to get conn: dial tcp <nil>->10.244.3.228:8300: i/o timeout"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.847Z [WARN]  agent.cache: handling error in Cache.Notify: cache-type=resolved-service-config error="rpc error getting client: failed to get conn: dial tcp <nil>->10.244.3.228:8300: i/o timeout" index=0
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.847Z [ERROR] agent: error handling service update: error="error watching service config: rpc error getting client: failed to get conn: dial tcp <nil>->10.244.3.228:8300: i/o timeout"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.847Z [ERROR] agent.client: RPC failed to server: method=Intention.Match server=10.244.3.228:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.847Z [WARN]  agent.cache: handling error in Cache.Notify: cache-type=intention-match error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection" index=0
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.847Z [ERROR] agent.client: RPC failed to server: method=Catalog.NodeServiceList server=10.244.3.228:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.847Z [ERROR] agent.proxycfg: Failed to handle update from watch: kind=connect-proxy proxy=edge-proxy-01-sidecar-proxy service_id=edge-proxy-01-sidecar-proxy id=intentions error="error filling agent cache: rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.847Z [ERROR] agent.anti_entropy: failed to sync remote state: error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.847Z [ERROR] agent.client: RPC failed to server: method=ConfigEntry.Get server=10.244.3.228:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.847Z [ERROR] agent.client: RPC failed to server: method=ConnectCA.Roots server=10.244.3.228:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.847Z [ERROR] agent.client: RPC failed to server: method=ConfigEntry.List server=10.244.3.228:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.848Z [WARN]  agent.cache: handling error in Cache.Notify: cache-type=config-entries error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection" index=0
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.848Z [ERROR] agent.proxycfg: Failed to handle update from watch: kind=connect-proxy proxy=edge-proxy-01-sidecar-proxy service_id=edge-proxy-01-sidecar-proxy id=jwt-provider error="error filling agent cache: rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.848Z [WARN]  agent.cache: handling error in Cache.Notify: cache-type=config-entry error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection" index=0
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.848Z [ERROR] agent.proxycfg: Failed to handle update from watch: kind=connect-proxy proxy=edge-proxy-01-sidecar-proxy service_id=edge-proxy-01-sidecar-proxy id=mesh error="error filling agent cache: rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.848Z [WARN]  agent.leaf-certs: handling error in Manager.Notify: error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection" index=1
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.848Z [WARN]  agent.cache: handling error in Cache.Notify: cache-type=connect-ca-root error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection" index=0
Feb 04 14:59:45 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:45.848Z [ERROR] agent.proxycfg: Failed to handle update from watch: kind=connect-proxy proxy=edge-proxy-01-sidecar-proxy service_id=edge-proxy-01-sidecar-proxy id=roots error="error filling agent cache: rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:47 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:47.105Z [WARN]  agent: Check TCP connection failed: check=service:edge-proxy-01-sidecar-proxy:1 error="dial tcp 127.0.0.1:21000: connect: connection refused"
Feb 04 14:59:47 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:47.105Z [WARN]  agent: Check is now critical: check=service:edge-proxy-01-sidecar-proxy:1
Feb 04 14:59:49 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:49.323Z [ERROR] agent.client.memberlist.lan: memberlist: Push/Pull with consul-server-2 failed: dial tcp 10.244.3.228:8301: i/o timeout
Feb 04 14:59:50 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:50.695Z [INFO]  agent.client.memberlist.lan: memberlist: Suspect klusterx-worker-infra-04 has failed, no acks received
Feb 04 14:59:55 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:55.848Z [ERROR] agent.client: RPC failed to server: method=ConfigEntry.Get server=10.244.5.248:8300 error="rpc error getting client: failed to get conn: dial tcp <nil>->10.244.5.248:8300: i/o timeout"
Feb 04 14:59:55 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:55.848Z [ERROR] agent.client: RPC failed to server: method=ConfigEntry.List server=10.244.5.248:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:55 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:55.848Z [ERROR] agent.client: RPC failed to server: method=ConfigEntry.ResolveServiceConfig server=10.244.5.248:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:55 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:55.848Z [ERROR] agent.client: RPC failed to server: method=Catalog.NodeServiceList server=10.244.5.248:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:55 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:55.848Z [ERROR] agent.anti_entropy: failed to sync remote state: error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:55 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:55.848Z [ERROR] agent.client: RPC failed to server: method=ConnectCA.Roots server=10.244.5.248:8300 error="rpc error getting client: failed to get conn: rpc error: lead thread didn't get connection"
Feb 04 14:59:55 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:55.863Z [WARN]  agent: [core][Channel #1 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "central-primary-infra-10.244.3.228:8300", ServerName: "consul-server-2", }. Err: connection error: desc = "transport: Error while dialing: dial tcp <nil>->10.244.3.228:8300: i/o timeout"
Feb 04 14:59:55 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:55.863Z [WARN]  agent.cache: handling error in Cache.Notify: cache-type=trust-bundles error="rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing: dial tcp <nil>->10.244.3.228:8300: i/o timeout\"" index=0
Feb 04 14:59:55 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:55.863Z [ERROR] agent.proxycfg: Failed to handle update from watch: kind=connect-proxy proxy=edge-proxy-01-sidecar-proxy service_id=edge-proxy-01-sidecar-proxy id=peering-trust-bundles error="error filling agent cache: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing: dial tcp <nil>->10.244.3.228:8300: i/o timeout\""
Feb 04 14:59:57 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:57.106Z [WARN]  agent: Check TCP connection failed: check=service:edge-proxy-01-sidecar-proxy:1 error="dial tcp 127.0.0.1:21000: connect: connection refused"
Feb 04 14:59:57 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:57.106Z [WARN]  agent: Check is now critical: check=service:edge-proxy-01-sidecar-proxy:1
Feb 04 14:59:58 klusterx-envoyingress-01 consul[4443]: 2026-02-04T14:59:58.696Z [INFO]  agent.client.memberlist.lan: memberlist: Suspect consul-server-2 has failed, no acks received
--------------------------------------------------



onsul-server-0           10.244.5.142:8301  alive   server  1.22.2  2         central-primary-infra  default    <all>
consul-server-1           10.244.1.128:8301  alive   server  1.22.2  2         central-primary-infra  default    <all>
consul-server-2           10.244.3.187:8301  alive   server  1.22.2  2         central-primary-infra  default    <all>
envoy-edge-01             10.19.143.93:8301  alive   client  1.22.2  2         central-primary-infra  default    <default>
klusterx-worker-infra-01  10.244.4.15:8301   failed  client  1.22.2  2         central-primary-infra  default    <default>
klusterx-worker-infra-02  10.244.1.171:8301  alive   client  1.22.2  2         central-primary-infra  default    <default>
klusterx-worker-infra-04  10.244.5.236:8301  alive   client  1.22.2  2         central-primary-infra  default    <default>
klusterx-worker-infra-05  10.244.3.5:8301    alive   client  1.22.2  2         central-primary-infra  default    <default>
root@klusterx-envoyingress-01:~# ip route 10.244.5.142
Command "10.244.5.142" is unknown, try "ip route help".
root@klusterx-envoyingress-01:~# ip route get 10.244.5.142
10.244.5.142 via 10.19.143.1 dev enp6s18 src 10.19.143.93 uid 0 
    cache 
root@klusterx-envoyingress-01:~# ip route get 10.244.5.128
10.244.5.128 via 10.19.143.1 dev enp6s18 src 10.19.143.93 uid 0 
    cache 
root@klusterx-envoyingress-01:~# ip route get 10.244.5.187
10.244.5.187 via 10.19.143.1 dev enp6s18 src 10.19.143.93 uid 0 
    cache 


-------------

cat CiliumBGPAdvertisement.yaml


apiVersion: cilium.io/v2
kind: CiliumBGPClusterConfig
metadata:
  name: bgp-config
spec:
  nodeSelector:
    matchLabels:
      cilium-bgp: "enabled"
  bgpInstances:
    - name: "instance-64513"
      localASN: 64513
      peers:
        - name: "proxmox-host"
          peerASN: 64512
          peerAddress: "10.19.143.94"
          peerConfigRef:
            name: "proxmox-peer-config"
---
apiVersion: cilium.io/v2
kind: CiliumBGPPeerConfig
metadata:
  name: "proxmox-peer-config"
spec:
  families:
    - afi: ipv4
      safi: unicast
      advertisements:
        matchLabels:
          advertise: "true"   # selects CiliumBGPAdvertisement below
---
apiVersion: cilium.io/v2
kind: CiliumBGPAdvertisement
metadata:
  name: "bgp-advertisements"
  labels:
    advertise: "true"
spec:
  advertisements:
    - advertisementType: "Service"
      service:
        addresses:
          - "LoadBalancerIP"
      selector:
        matchLabels:
          advertise: "true"
----
 kubectl apply -f  CiliumBGPAdvertisement.yaml
ciliumbgpclusterconfig.cilium.io/bgp-config unchanged
ciliumbgppeerconfig.cilium.io/proxmox-peer-config unchanged
The CiliumBGPAdvertisement "bgp-advertisements" is invalid:
* spec.advertisements[1].advertisementType: Unsupported value: "podCIDR": supported values: "PodCIDR", "CiliumPodIPPool", "Service"
* <nil>: Invalid value: null: some validation rules were not checked because the object was invalid; correct the existing errors to complete validation

----

kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{" "}{.spec.podCIDR}{"\n"}{end}'

kubectl -n kube-system logs ds/cilium | grep -i podcidr

